{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Abstractive Summarization of Long Podcast Transcripts with BART using Semantic Self-segmentation\n",
    "Podcasts are a rapidly growing medium for news, commentary, entertainment, and learning.  Some podcast shows release new episodes on a regular schedule (daily, weekly, etc); others irregularly.  Some podcast shows feature short episodes of 5 minutes or less touching on one or two topics; others may release 3+ hour long episodes touching on a wide range of topics.  Some are structured as news delivery, some as conversations, some as storytelling.\n",
    "\n",
    "Given a podcast episode, its audio, and transcription, return a short text snippet capturing the most important information in the content. Returned summaries should be grammatical, standalone statement of significantly shorter length than the input episode description.\n",
    "\n",
    "The user task is to provide a short text summary that the user might read when deciding whether to listen to a podcast. Thus the summary should accurately convey the content of the podcast, and be short enough to quickly read on a smartphone screen. It should also be human-readable.\n",
    "\n",
    "For further information about the challenge, take a look to Podcasts Track Guidelines:\n",
    "- [TREC 2020 Podcasts Track](https://trecpodcasts.github.io/participant-instructions-2020.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import pysbd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  Index(['show_uri', 'show_name', 'show_description', 'publisher', 'language',\n",
      "       'rss_link', 'episode_uri', 'episode_name', 'episode_description',\n",
      "       'duration', 'show_filename_prefix', 'episode_filename_prefix'],\n",
      "      dtype='object')\n",
      "Shape:  (105360, 12)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.path.abspath(\"D:/\"), 'podcasts-no-audio-13GB')\n",
    "\n",
    "metadata_path_train = os.path.join(dataset_path, 'metadata.tsv')\n",
    "metadata_train = pd.read_csv(metadata_path_train, sep='\\t')\n",
    "print(\"Columns: \", metadata_train.columns)\n",
    "print(\"Shape: \", metadata_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(episode):\n",
    "    \"\"\"\n",
    "    Get the path of the episode json file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : pandas.Series\n",
    "        A row from the metadata file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    path : str\n",
    "        The absolute path of the episode json file\n",
    "    \"\"\"\n",
    "    # extract the 2 reference number/letter to access the episode transcript\n",
    "    show_filename = episode['show_filename_prefix']\n",
    "    episode_filename = episode['episode_filename_prefix'] + \".json\"\n",
    "    dir_1, dir_2 = re.match(r'show_(\\d)(\\w).*', show_filename).groups()\n",
    "\n",
    "    # check if the transcript file in all the derived subfolders exist\n",
    "    transcipt_path = os.path.join(dataset_path, \"spotify-podcasts-2020\",\n",
    "                                \"podcasts-transcripts\", dir_1, dir_2,\n",
    "                                show_filename, episode_filename)\n",
    "    return transcipt_path\n",
    "\n",
    "def get_transcription(episode):\n",
    "    \"\"\"\n",
    "    Extract the transcript from the episode json file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : pandas.Series\n",
    "        A row from the metadata file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    transcript : str\n",
    "        The transcript of the episode\n",
    "    \"\"\"\n",
    "    with open(get_path(episode), 'r') as f:\n",
    "        episode_json = json.load(f)\n",
    "        # seems that the last result in each trastcript is a repetition of the first one, so we ignore it\n",
    "        transcripts = [\n",
    "            result[\"alternatives\"][0]['transcript'] if 'transcript' in result[\"alternatives\"][0] else \"\"\n",
    "            for result in episode_json[\"results\"][:-1]\n",
    "        ]\n",
    "        return \" \".join(transcripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics about episode duration:\n",
      "count    105360.000000\n",
      "mean         33.845715\n",
      "std          22.735674\n",
      "min           0.175317\n",
      "25%          13.552638\n",
      "50%          31.643375\n",
      "75%          50.446825\n",
      "max         304.953900\n",
      "Name: duration, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Statistics about episode duration:\\n\"\n",
    "      f\"{metadata_train['duration'].describe()}\")\n",
    "metadata_train['duration'].hist(bins=1000, figsize=(10,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics about number of episodes per show:\n",
      "count    18376.000000\n",
      "mean         5.733566\n",
      "std         19.310585\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max       1072.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_episodes = metadata_train.groupby(['show_filename_prefix']).apply(lambda x: list(zip(x['episode_filename_prefix'], x['episode_description']))).to_dict()\n",
    "show_n_episodes = {k: len(v) for k, v in show_episodes.items()}\n",
    "print(\"Statistics about number of episodes per show:\\n\"\n",
    "      f\"{pd.Series(show_n_episodes.values()).describe()}\")\n",
    "pd.Series(show_n_episodes.values()).hist(bins=1000, figsize=(10,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Dataset cleaning\n",
    "\n",
    "Some of the episodes contain a `NaN` value in the `episode_description` and `show_description` columns. Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping NaN values: \n",
      " show_uri                   False\n",
      "show_name                  False\n",
      "show_description            True\n",
      "publisher                  False\n",
      "language                   False\n",
      "rss_link                   False\n",
      "episode_uri                False\n",
      "episode_name               False\n",
      "episode_description         True\n",
      "duration                   False\n",
      "show_filename_prefix       False\n",
      "episode_filename_prefix    False\n",
      "dtype: bool\n",
      "\n",
      "After dropping NaN values:\n",
      " show_uri                   False\n",
      "show_name                  False\n",
      "show_description           False\n",
      "publisher                  False\n",
      "language                   False\n",
      "rss_link                   False\n",
      "episode_uri                False\n",
      "episode_name               False\n",
      "episode_description        False\n",
      "duration                   False\n",
      "show_filename_prefix       False\n",
      "episode_filename_prefix    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"Before dropping NaN values: \\n\", metadata_train.isna().any())\n",
    "metadata_train.dropna(subset=['episode_description', 'show_description'], inplace=True)\n",
    "print(\"\\nAfter dropping NaN values:\\n\", metadata_train.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select a subset of the corpus that is suitable for training supervised models, we filtered the descriptions using three heuristics shown in the table below. These filters overlap to some extent, and remove about a third of the entire set. The remaining episodes we call the **Brass Set**.\n",
    "\n",
    "| Criterion                        | Threshold                                                    |\n",
    "| -------------------------------- | ------------------------------------------------------------ |\n",
    "| Length                           | descriptions that are very long (> 750 characters) or short (< 20 characters). |\n",
    "| Similarity to show description   | descriptions with high lexical overlap (over 40%) with their show description. |\n",
    "| Similarity to other descriptions | descriptions with high lexical overlap (over 50%) with other episode descriptions in the same show. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lenght_brass(episode, upper_bound=750, lower_bound=20):\n",
    "    \"\"\"\n",
    "    Check if the episode descriptions is not too long (> 750 characters) or not too short (< 20 characters)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : pandas.Series\n",
    "        A row from the metadata file\n",
    "    upper_bound : int\n",
    "        The upper bound of the episode description length\n",
    "    lower_bound : int\n",
    "        The lower bound of the episode description length\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Boolean indicating if the episode description is long enough\n",
    "    \"\"\"\n",
    "    return len(episode['episode_description']) <= upper_bound and len(episode['episode_description']) >= lower_bound\n",
    "    \n",
    "def description_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Measure the overlapping between two descriptions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : str\n",
    "        The first description\n",
    "    b : str\n",
    "        The second description\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Value indicating the overlapping between the two descriptions\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def check_show_description_overlap_brass(episode, thresh=0.4):\n",
    "    \"\"\"\n",
    "    Check if the episode descriptions overlapping with the show description is not too high (< 0.4)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : pandas.Series\n",
    "        A row from the metadata file\n",
    "    thresh : float\n",
    "        The threshold of the overlap between the episode description and the show description\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Boolean indicating if the episode description is different enough from the show description\n",
    "    \"\"\"\n",
    "    return description_similarity(episode['show_description'], episode['episode_description']) < thresh\n",
    "    \n",
    "def check_other_description_overlap_brass(episode, show_episodes, thresh=0.5):\n",
    "    \"\"\"\n",
    "    Check if the episode descriptions overlapping with the other description in the same show is not too high (< 0.5)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : pandas.Series\n",
    "        A row from the metadata file\n",
    "    show_episodes : dict\n",
    "        A dictionary of the episodes of the same show\n",
    "    thresh : float\n",
    "        The threshold of the overlap between the episode description and the other description\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Boolean indicating if the episode description is different enough from the other description\n",
    "    \"\"\"\n",
    "    for other_prefix, other_description in show_episodes[episode['show_filename_prefix']]:\n",
    "        if other_prefix != episode['episode_filename_prefix'] and description_similarity(episode['episode_description'], other_description) > thresh and len(episode['episode_description']) < other_description:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "brass_set_lenght = metadata_train[metadata_train.progress_apply(check_lenght_brass, axis=1)]\n",
    "print(f\"Removed {len(metadata_train) - len(brass_set_lenght)} episodes ({(100-(len(brass_set_lenght)/len(metadata_train)*100)):.2f}%) because of too long or too short descriptions\")\n",
    "\n",
    "brass_set_show_overlap = brass_set_lenght[brass_set_lenght.progress_apply(check_show_description_overlap_brass, axis=1)]\n",
    "print(f\"Removed {len(brass_set_lenght) - len(brass_set_show_overlap)} episodes ({(100-(len(brass_set_show_overlap)/len(brass_set_lenght)*100)):.2f}%) because of too high overlap with the show description\")\n",
    "\n",
    "show_episodes = brass_set_show_overlap.groupby(['show_filename_prefix']).apply(lambda x: list(zip(x['episode_filename_prefix'], x['episode_description']))).to_dict()\n",
    "brass_set = brass_set_show_overlap[brass_set_show_overlap.progress_apply(lambda x: check_other_description_overlap_brass(x, show_episodes), axis=1)]\n",
    "print(f\"Removed {len(brass_set_show_overlap) - len(brass_set)} episodes ({(100-(len(brass_set)/len(brass_set_show_overlap)*100)):.2f}%) because of too high overlap with other descriptions in the same show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store brass set\n",
    "brass_set.to_csv(os.path.join(os.path.dirname(metadata_path_train), \"brass_set.tsv\"), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode description: \n",
      "\tTwo unlicensed, unprofessional, uncensored sisters, August and Indie, give you all the advice you could possibly need and more. Fielding questions from the audience on patios around the world, the sister duo will give their hottest takes. Tune in and subscribe to join in on the fun! Submit questions to adviceonthepatio@gmail.com to receive some wisdom.  \n",
      "Show description: \n",
      "\tTwo unlicensed, unprofessional, uncensored sisters, August and Indie, give advice on patios around the world.\n",
      "Overlapping score: \n",
      "\t0.43010752688172044\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tWelcome to The Blue Lot where John and Zach talk college and pro sports, with an emphasis on West Virginia, and make a few jokes along the way. Today we talked WVU Basketball, the College Football Playoff Championship, and the NFL Playoffs. Follow us on Twitter @BlueLotPod and individually @ZCampbell_SI & @John_Pentol_ \n",
      "Show description: \n",
      "\tWelcome to The Blue Lot where John and Zach talk college and pro sports, with an emphasis on West Virginia, and make a few jokes along the way. Follow us on Twitter @BlueLotPod \n",
      "Overlapping score: \n",
      "\t0.7108433734939759\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tKeena explains why in life, there are no do-overs.   ---   Send in a voice message: https://anchor.fm/xperience-j/message Support this podcast: https://anchor.fm/xperience-j/support\n",
      "Show description: \n",
      "\tUnderwhelmed by life and overwhelmed by disappointments, a 30-year-old writer and entrepreneur takes an introspective look at her life, and its shortcomings. Has her time come and gone, or is she simply a late bloomer? Support this podcast: https://anchor.fm/xperience-j/support\n",
      "Overlapping score: \n",
      "\t0.4008714596949891\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tEpisode for 3 December, 2019  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/australianmb/support\n",
      "Show description: \n",
      "\tA morning show condensing essential market information into a few minutes, to brief you for the upcoming day. Contains leading market stories across all stock markets, commodity markets and political stories of note.    Support this podcast: https://anchor.fm/australianmb/support\n",
      "Overlapping score: \n",
      "\t0.40421052631578946\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tPodcast hosted by Tyler Mowels and Peter Zachowicz. Short introduction to the two hosts and small discussions about other topics.                                               Email: ontheroadpodcasts@gmail.com Twitter: @OnTheRoadPod  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app \n",
      "Show description: \n",
      "\tPodcast hosted by Tyler Mowels and Peter Zachowicz broadcasted from the road. Our topics include mental health, movies, books, personal anecdotes, and more.   Email: ontheroadpodcasts@gmail.com Twitter: @OnTheRoadPod \n",
      "Overlapping score: \n",
      "\t0.4064748201438849\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tMoudi Tajjour & UC Brigante come together for the 14th episode of their Can't Fight Fate Podcast, they talk about getting raided and dumped in the same week and more. \n",
      "Show description: \n",
      "\tMoudi Tajjour & UC Brigante come together as an interesting duo to bring you the Can't Fight Fate podcasts weekly. \n",
      "Overlapping score: \n",
      "\t0.5602836879432624\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tBasic information on what Wiccantations is, how the podcast will be formatted, and who Nova, the host, is.   ---   Support this podcast: https://anchor.fm/wiccantations/support\n",
      "Show description: \n",
      "\tWiccantations is a podcast for intersectional feminists, witches, and wiccans alike with a focus on current events, tarot, and life as a person of color (aka, my day-to-day life). Support this podcast: https://anchor.fm/wiccantations/support\n",
      "Overlapping score: \n",
      "\t0.5419664268585132\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tFind out to how to overcome codependency and take your power back after narcissistic abuse.  \n",
      "Show description: \n",
      "\tInsights on narcissism and techniques on how to heal after narcissistic abuse.\n",
      "Overlapping score: \n",
      "\t0.5029239766081871\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tOn this new podcast, Tony Thaxton tells the story behind the strange albums that you can't believe actually exist.   ---   Support this podcast: https://anchor.fm/bizarrealbums/support\n",
      "Show description: \n",
      "\tTony Thaxton explores the weirder side of music, celebrating and telling the story behind those strange albums that make you wonder how and why they exist. Doing deep dives on albums released by pro athletes, actors, fictional characters, and more. Support this podcast: https://anchor.fm/bizarrealbums/support Support this podcast: https://anchor.fm/bizarrealbums/support\n",
      "Overlapping score: \n",
      "\t0.5107913669064749\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tFrom the medium-sized town that reinvented print journalism comes Generation Betoota, a weekly youth news podcast featuring stories young people care about using the hip language they're fluent in.\n",
      "Show description: \n",
      "\tFrom the medium-sized town that reinvented print journalism comes Generation Betoota, a weekly youth news podcast featuring stories young people care about using the hip language they're fluent in.\n",
      "Overlapping score: \n",
      "\t1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look to the removed episode descriptions due to the overlap with the show description\n",
    "removed_episodes_show_overlap = pd.concat([brass_set_lenght, brass_set_show_overlap]).drop_duplicates(keep=False)[['show_description', 'episode_description']]\n",
    "removed_episodes_show_overlap['overlapping'] = removed_episodes_show_overlap.apply(lambda row: description_similarity(row['show_description'], row['episode_description']), axis=1)\n",
    "\n",
    "num_to_visualize = 10\n",
    "\n",
    "for _ in range(num_to_visualize):\n",
    "    row = removed_episodes_show_overlap.sample()\n",
    "    print(f\"Episode description: \\n\\t{row['episode_description'].values[0]}\")\n",
    "    print(f\"Show description: \\n\\t{row['show_description'].values[0]}\")\n",
    "    print(f\"Overlapping score: \\n\\t{row['overlapping'].values[0]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode description: \n",
      "\tIn this episode I talk about feet pics, rating dick pics, sugar daddies, etc. AKA the weirdos that lurk the net  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app \n",
      "EOther episode description: \n",
      "\tIn this episode we talk about hookups, talking, bad dates, cheating, crazy exes and more!  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app \n",
      "Overlapping score: \n",
      "\t0.7330097087378641\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tThis is Stephanie McCurrach’s take On God. \n",
      "EOther episode description: \n",
      "\tThis is Evan Ash’s take On God.  \n",
      "Overlapping score: \n",
      "\t0.7368421052631579\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tWe delve into my why. Why I started this podcast and a bit of a personal story. So here's me going on this journey to learn more and sharing that all with you. To check out other projects and initiatives I'm working on, feel free to follow me on Instagram, Twitter and LinkedIn. Know any experts in this field? or maybe that's you? I'd love to chat and share more knowledge out to the world together. You can book in a time to chat with me here. \n",
      "EOther episode description: \n",
      "\tWe delve into my why. Why I started this podcast and a bit of a personal story. So here's me going on this journey to learn more and sharing that all with you. To check out other projects and initiatives I'm working on, feel free to follow me on Instagram, Twitter and LinkedIn. Know any experts in this field? or maybe that's you? I'd love to chat and share more knowledge out to the world together. You can book in a time to chat with me here. \n",
      "Overlapping score: \n",
      "\t1.0\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tOne thing I’m working on lately for my life personally, is setting standards with people. Who I am, what I want, what I deserve, and I’m here to encourage you to do the same. Never settle for less than what you deserve.   ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app \n",
      "EOther episode description: \n",
      "\tFind your tribe and love them hard.   ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app \n",
      "Overlapping score: \n",
      "\t0.5427350427350427\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tDenzil Meyrick and Douglas Skelton host the first episode of SBOOKS, complete with barking dog.   ---   Send in a voice message: https://anchor.fm/sbooks/message\n",
      "EOther episode description: \n",
      "\tAlex Kane, Scotland's answer to Martina Cole, talks to Denzil Meyrick about books, life and knowing where you are in Spain.   ---   Send in a voice message: https://anchor.fm/sbooks/message\n",
      "Overlapping score: \n",
      "\t0.5314285714285715\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tJoin us as we discuss our top Netflix recommendations, the climate and the Mandela Effect!  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/idwtai/message\n",
      "EOther episode description: \n",
      "\tJoin us as we discuss our top Netflix recommendations, the climate and the Mandela Effect!  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/idwtai/message\n",
      "Overlapping score: \n",
      "\t1.0\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tI'm joined by my brother and sister as we sit and talk for the first time in awhile!  Drugs are bad m'kay.  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/roberto-carlos-barrera/support\n",
      "EOther episode description: \n",
      "\tI'm joined by my brother and sister as we sit and talk for the first time in awhile!  Drugs are bad m'kay.  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/roberto-carlos-barrera/support\n",
      "Overlapping score: \n",
      "\t1.0\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tDON'T WASTE YOUR LIFE - Powerful #MotivationalSpeech \n",
      "EOther episode description: \n",
      "\tDON'T WASTE YOUR LIFE - Powerful #MotivationalSpeech \n",
      "Overlapping score: \n",
      "\t1.0\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tSam has the worth ethic, intent and is always learning. He’s doing the fitness hustle and really wants to help people. Check out both his coaching & day-to-day accounts on IG: https://instagram.com/coachsamchang https://instagram.com/crippledlifter  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app \n",
      "EOther episode description: \n",
      "\tThis episode could change your life.  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app \n",
      "Overlapping score: \n",
      "\t0.5120967741935484\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tGet to know us as we dive dive in head first into the world of podcasting.  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/dimeughdozen/support\n",
      "EOther episode description: \n",
      "\tGet to know us as we dive dive in head first into the world of podcasting.  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/dimeughdozen/support\n",
      "Overlapping score: \n",
      "\t1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look to the removed episode descriptions due to the overlap with the other episode descriptions in the same show\n",
    "removed_episodes_other_overlap = pd.concat([brass_set, brass_set_show_overlap]).drop_duplicates(keep=False)[['show_filename_prefix', 'episode_filename_prefix', 'episode_description']]\n",
    "two_episodes_show  = {str(show_filename_prefix): show_episodes[show_filename_prefix] for show_filename_prefix in removed_episodes_other_overlap['show_filename_prefix'] if len(show_episodes[show_filename_prefix]) == 2 }\n",
    "removed_episodes_other_overlap = removed_episodes_other_overlap[removed_episodes_other_overlap['show_filename_prefix'].isin(two_episodes_show.keys())]\n",
    "other_episode_show = {}\n",
    "for i, row in removed_episodes_other_overlap.iterrows():\n",
    "    if row['show_filename_prefix'] in two_episodes_show:\n",
    "        if row['episode_filename_prefix'] in two_episodes_show[row['show_filename_prefix']][0]:\n",
    "            other_episode_show[row['show_filename_prefix']] = two_episodes_show[row['show_filename_prefix']][1][1]\n",
    "        else:\n",
    "            other_episode_show[row['show_filename_prefix']] = two_episodes_show[row['show_filename_prefix']][0][1]\n",
    "removed_episodes_other_overlap['other_episode_description'] = removed_episodes_other_overlap.apply(lambda row: other_episode_show[row['show_filename_prefix']], axis=1)\n",
    "removed_episodes_other_overlap['overlapping'] = removed_episodes_other_overlap.apply(lambda row: description_similarity(row['episode_description'], row['other_episode_description']), axis=1)\n",
    "\n",
    "num_to_visualize = 10\n",
    "\n",
    "for _ in range(num_to_visualize):\n",
    "    row = removed_episodes_other_overlap.sample()\n",
    "    print(f\"Episode description: \\n\\t{row['episode_description'].values[0]}\")\n",
    "    print(f\"EOther episode description: \\n\\t{row['other_episode_description'].values[0]}\")\n",
    "    print(f\"Overlapping score: \\n\\t{row['overlapping'].values[0]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Further cleaning of the data\n",
    "The podcast episodes should be restricted to the English language, but they cover a range of geographical regions and we found a number of non-English podcasts in the dataset. So we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens that correspond to URLs, email addresses, @mentions, #hashtags, and those excessively long tokens (>25 characters) are directly removed from the summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We futher cleaned the descriptions computing a *salience score* for each sentence of the description by summing over word IDF scores.\n",
    "Then we remove sentences if their salience scores are lower than a threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Golden set integration\n",
    "In addition we have a **golden set** of 150 episodes composed by 6 set of summaries for each episode (900 document-summary-grade triplets) that were graded on the Bad/Fair/Good/Excellent scale (0-3). We integrated the best summary of each episodes in the *brass set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6  Chunck classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_ahead_chuck(sentences, lower_chunk_size):\n",
    "    \"\"\"\n",
    "    Look-ahead function to determine the next chunk\n",
    "    \"\"\"\n",
    "    if sum([len(s) for s in sentences]) < lower_chunk_size:\n",
    "        # if the remaining sentences size is smaller than the lower bound, we return the remaining sentences\n",
    "        return sentences\n",
    "    else:\n",
    "        # next chunk size should be at least the lower bound \n",
    "        for i in range(len(sentences)):\n",
    "            if sum([len(s) for s in sentences[:i+1]]) >= lower_chunk_size:\n",
    "                return sentences[:i+1]\n",
    "\n",
    "\n",
    "def semantic_segmentation(text, model, lower_chunk_size=300, upper_chunk_size=2000):\n",
    "    \"\"\"\n",
    "    Algorithm proposed by Moro et. al. (2022) to semantically segment long inputs into GPU memory-adaptable chunks.\n",
    "    https://www.aaai.org/AAAI22Papers/AAAI-3882.MoroG.pdf\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    text: str\n",
    "        The text to be segmented\n",
    "    model: SentenceTransformer\n",
    "        The model to be used for the sentence embeddings\n",
    "    lower_chunk_size: int\n",
    "        The lower bound of the chunk size\n",
    "    upper_chunk_size: int\n",
    "        The upper bound of the chunk size\n",
    "    Return\n",
    "    -------\n",
    "    List of chunks of text\n",
    "    \"\"\"\n",
    "\n",
    "    # segment the text into sentences\n",
    "    seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "    sentences = seg.segment(text)\n",
    "\n",
    "    chuncks = []\n",
    "    current_chunk = [sentences[0]]\n",
    "\n",
    "    # Iterate over the sentences in the text\n",
    "    for i, sentence in enumerate(sentences[1:]):\n",
    "        if sentence == sentences[-1]:\n",
    "            # If the sentence is the last one, we add it to the last chunk\n",
    "            current_chunk.append(sentence)\n",
    "            chuncks.append(current_chunk)\n",
    "        elif sum([len(s) for s in current_chunk]) + len(sentence) < lower_chunk_size:\n",
    "            # standardize each chunk to a minimum size to best leverage the capability of Transformers\n",
    "            current_chunk.append(sentence)\n",
    "        elif sum([len(s) for s in current_chunk]) + len(sentence) > upper_chunk_size:\n",
    "            # if the chunk is too big, we add it to the list of chunks and start a new one\n",
    "            chuncks.append(current_chunk)\n",
    "            current_chunk = [sentence]\n",
    "        else:\n",
    "            idx = i+1\n",
    "            next_chuck = look_ahead_chuck(sentences[idx+1:], lower_chunk_size)\n",
    "            \n",
    "            # get the embedding of the previous chunk and the next chunk\n",
    "            current_embedding = model.encode(current_chunk)\n",
    "            next_embedding = model.encode(next_chuck)\n",
    "            sentence_embedding = model.encode([sentence])\n",
    "\n",
    "            # get the cosine similarity between the embedding of the embeddings\n",
    "            score_current_chunk = util.cos_sim(sentence_embedding, current_embedding).numpy().mean()\n",
    "            score_next_chunk = util.cos_sim(sentence_embedding, next_embedding).numpy().mean()\n",
    "\n",
    "            # if the score_current_chunk is higher than the score_next_chunk, we add the sentence to the current chunk\n",
    "            if score_current_chunk > score_next_chunk:\n",
    "                current_chunk.append(sentence)\n",
    "            else:\n",
    "                if sum([len(s) for s in current_chunk]) >= lower_chunk_size:\n",
    "                    chuncks.append(current_chunk)\n",
    "                    current_chunk = [sentence]\n",
    "                else:\n",
    "                    current_chunk.append(sentence)\n",
    "    return chuncks\n",
    "\n",
    "# Initialize the sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "semantic_segmentation(get_transcription(metadata_train.iloc[105325]), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Chunk Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each chunk an encoding of each sentence is extracted using a pretrained RoBerta Transformerss to obtain a dense encoding. The encoding of the chunk is the mean of the encoding of its sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    def extract_features(self,text):\n",
    "        \"\"\"\n",
    "        Extract features from text using a mean of the tf-idf\n",
    "        Parameters:\n",
    "            - text: string representing a document\n",
    "        Returns:\n",
    "            - extracted features\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        for sentence in text:\n",
    "          embeddings.append(self.model.encode(sentence))\n",
    "\n",
    "        features = np.mean(embeddings, axis=0)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep only useful chunks for each transcript we compare the chunk with the corresponding summary of the transcript it belongs to and, if the score obtained with a certain metric is below a threshold (strictly coupled with the metric), the chunk is not taken into account as a part of the transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isChunkUseful(chunk, summary, metric, threshold):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - chunk: part of the transcript\n",
    "        - summary: summary of a transcript\n",
    "        - metric: function of ariety 2 (chunk, summary) used to evaluate the summary\n",
    "        - threshold: value used to decide whether chunk is a good summary or not\n",
    "    Returns:\n",
    "        - True if the chunk is a good summary, False otherwise\n",
    "    \"\"\"\n",
    "    score = metric(chunk, summary)\n",
    "    if score < threshold:\n",
    "        result = False\n",
    "    else:\n",
    "        result = True\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen metric is BERTscore f1-score because it is a semantic metric, i.e. it takes into account the meaning of words in the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bertscore_f1_score(reference, candidate):\n",
    "    \"\"\"\n",
    "    BERTScore score, see https://github.com/huggingface/datasets/tree/master/metrics/bertscore for API\n",
    "    Parameters:\n",
    "        reference: reference translation\n",
    "        candidate: generated translation\n",
    "    Returns:\n",
    "        BERTScore f1 score\n",
    "    \"\"\"\n",
    "    bertscore = load_metric(\"bertscore\")\n",
    "    result = bertscore.compute(\n",
    "        predictions=[candidate],\n",
    "        references=[reference],\n",
    "        lang=\"en\",\n",
    "        rescale_with_baseline=True\n",
    "    )\n",
    "    return result['f1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "metric = bertscore_f1_score\n",
    "\n",
    "# creation of the dataset for chunk classification\n",
    "# creation of the targets\n",
    "\n",
    "print(f\"total number of episodes: {len(metadata_train)}\")\n",
    "\n",
    "#chunks = []\n",
    "#for i in range(len(metadata_train)):\n",
    "#    print(f\"Episode {i}\")\n",
    "#    chunk = semantic_segmentation(get_transcription(metadata_train.iloc[i]), model)\n",
    "#    chunks.append(chunk)\n",
    "\n",
    "targets = []\n",
    "\n",
    "for i in range(len(metadata_train)):\n",
    "    chunks = semantic_segmentation(get_transcription(metadata_train.iloc[i]), model)\n",
    "    for j in range(len(chunks)):\n",
    "        description = metadata_train.iloc[i].episode_description\n",
    "        if isChunkUseful(' '.join(chunks[j]), description, metric, threshold):\n",
    "            targets.append(1)\n",
    "        else:\n",
    "            targets.append(0)\n",
    "\n",
    "y = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of the features\n",
    "\n",
    "extractor = FeatureExtractor()\n",
    "features = []\n",
    "for i in len(metadata_train):\n",
    "    for j in range(len(chunks[i])):\n",
    "        chunk = chunks[i][j]\n",
    "        features.append(extractor.extract_features(chunk))\n",
    "\n",
    "X = np.array(features)\n",
    "\n",
    "# splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "catboost = CatBoostClassifier(iterations=2,\n",
    "                           learning_rate=1,\n",
    "                           depth=2)\n",
    "# Fit model\n",
    "catboost.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = catboost.predict(X_test)\n",
    "accuracy = accuracy(y, y_pred)\n",
    "\n",
    "print(f\"Accuracy of chunk selection: {round(accuracy,2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 256\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "\n",
    "model_checkpoint = \"facebook/bart-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(dataset, text_column, summary_column, max_input_length, max_target_length, padding, prefix=\"summarize: \"):\n",
    "    inputs = dataset[text_column]\n",
    "    targets = dataset[summary_column]\n",
    "    inputs = [prefix + inp for inp in inputs]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = \"max_length\"\n",
    "train_dataset = train_dataset.map(\n",
    "                lambda x: preprocess_function(x, \"transcript\", \"best_summary\", max_input_length, max_target_length, padding, prefix=\"summarize: \"),\n",
    "                batched=True,\n",
    "                remove_columns=train_dataset.column_names,\n",
    "                desc=\"Running tokenizer on train dataset\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def sample_generator(dataset, model, tokenizer, shuffle, pad_to_multiple_of=None):\n",
    "    if shuffle:\n",
    "        sample_ordering = np.random.permutation(len(dataset))\n",
    "    else:\n",
    "        sample_ordering = np.arange(len(dataset))\n",
    "    for sample_idx in sample_ordering:\n",
    "        example = dataset[int(sample_idx)]\n",
    "        # Handle dicts with proper padding and conversion to tensor.\n",
    "        example = tokenizer.pad(example, return_tensors=\"np\", pad_to_multiple_of=pad_to_multiple_of)\n",
    "        example = {key: tf.convert_to_tensor(arr, dtype_hint=tf.int32) for key, arr in example.items()}\n",
    "        if model is not None and hasattr(model, \"prepare_decoder_input_ids_from_labels\"):\n",
    "            decoder_input_ids = model.prepare_decoder_input_ids_from_labels(\n",
    "                labels=tf.expand_dims(example[\"labels\"], 0)\n",
    "            )\n",
    "            example[\"decoder_input_ids\"] = tf.squeeze(decoder_input_ids, 0)\n",
    "        yield example, example[\"labels\"]  # TF needs some kind of labels, even if we don't use them\n",
    "    return\n",
    "\n",
    "# region Helper functions\n",
    "def dataset_to_tf(dataset, model, tokenizer, total_batch_size, num_epochs, shuffle):\n",
    "    if dataset is None:\n",
    "        return None\n",
    "    train_generator = partial(sample_generator, dataset, model, tokenizer, shuffle=shuffle)\n",
    "    train_signature = {\n",
    "        feature: tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "        for feature in dataset.features\n",
    "        if feature != \"special_tokens_mask\"\n",
    "    }\n",
    "    if (\n",
    "        model is not None\n",
    "        and \"decoder_input_ids\" not in train_signature\n",
    "        and hasattr(model, \"prepare_decoder_input_ids_from_labels\")\n",
    "    ):\n",
    "        train_signature[\"decoder_input_ids\"] = train_signature[\"labels\"]\n",
    "    # This may need to be changed depending on your particular model or tokenizer!\n",
    "    padding_values = {\n",
    "        key: tf.convert_to_tensor(tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0, dtype=tf.int32)\n",
    "        for key in train_signature.keys()\n",
    "    }\n",
    "    padding_values[\"labels\"] = tf.convert_to_tensor(-100, dtype=tf.int32)\n",
    "    train_signature[\"labels\"] = train_signature[\"input_ids\"]\n",
    "    train_signature = (train_signature, train_signature[\"labels\"])\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "    tf_dataset = (\n",
    "        tf.data.Dataset.from_generator(train_generator, output_signature=train_signature)\n",
    "        .with_options(options)\n",
    "        .padded_batch(\n",
    "            batch_size=total_batch_size,\n",
    "            drop_remainder=True,\n",
    "            padding_values=(padding_values, np.array(-100, dtype=np.int32)),\n",
    "        )\n",
    "        .repeat(int(num_epochs))\n",
    "    )\n",
    "    return tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_batch_size = 2\n",
    "num_train_epochs = 3\n",
    "learning_rate = 5e-5\n",
    "tf_train_dataset = dataset_to_tf(\n",
    "            train_dataset,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            total_batch_size=total_train_batch_size,\n",
    "            num_epochs=num_train_epochs,\n",
    "            shuffle=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "# region Optimizer, loss and LR scheduling\n",
    "# Scheduler and math around the number of training steps.\n",
    "num_update_steps_per_epoch = len(train_dataset) // total_train_batch_size\n",
    "num_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate, num_train_steps=num_train_steps, num_warmup_steps=0\n",
    ")\n",
    "\n",
    "def masked_sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    # We clip the negative labels to 0 to avoid NaNs appearing in the output and\n",
    "    # fouling up everything that comes afterwards. The loss values corresponding to clipped values\n",
    "    # will be masked later anyway, but even masked NaNs seem to cause overflows for some reason.\n",
    "    # 1e6 is chosen as a reasonable upper bound for the number of token indices - in the unlikely\n",
    "    # event that you have more than 1 million tokens in your vocabulary, consider increasing this value.\n",
    "    # More pragmatically, consider redesigning your tokenizer.\n",
    "    losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        tf.clip_by_value(y_true, 0, int(1e6)), y_pred, from_logits=True\n",
    "    )\n",
    "    # Compute the per-sample loss only over the unmasked tokens\n",
    "    losses = tf.ragged.boolean_mask(losses, y_true != -100)\n",
    "    losses = tf.reduce_mean(losses, axis=-1)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "# region Metric\n",
    "metric = load_metric(\"rouge\")\n",
    "# endregion\n",
    "\n",
    "# region Training\n",
    "model.compile(loss={\"logits\": masked_sparse_categorical_crossentropy}, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "                tf_train_dataset,\n",
    "                epochs=int(num_train_epochs),\n",
    "                steps_per_epoch=num_update_steps_per_epoch,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transcript_exaple = train_data.iloc[45].transcript\n",
    "transcript_exaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best summarization\n",
    "train_data.iloc[45].best_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.reshape(tokenizer(transcript_exaple, max_length=max_input_length, padding=padding, truncation=True).input_ids, (1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output =model.generate(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd86b5c47339ba7c128568c1fdf273a8327309a329b63c3cc5de2095ec077d11"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
