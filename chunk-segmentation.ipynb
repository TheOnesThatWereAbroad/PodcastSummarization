{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import json\n",
    "import pysbd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.path.abspath(\"\"), 'podcasts-no-audio-13GB')\n",
    "\n",
    "metadata_path_train = os.path.join(dataset_path, 'metadata.tsv')\n",
    "metadata_train = pd.read_csv(metadata_path_train, sep='\\t')\n",
    "\n",
    "def get_path(episode):\n",
    "    # extract the 2 reference number/letter to access the episode transcript\n",
    "    show_filename = episode['show_filename_prefix']\n",
    "    episode_filename = episode['episode_filename_prefix'] + \".json\"\n",
    "    dir_1, dir_2 = re.match(r'show_(\\d)(\\w).*', show_filename).groups()\n",
    "\n",
    "    # check if the transcript file in all the derived subfolders exist\n",
    "    transcipt_path = os.path.join(dataset_path, \"spotify-podcasts-2020\",\n",
    "                                \"podcasts-transcripts\", dir_1, dir_2,\n",
    "                                show_filename, episode_filename)\n",
    "\n",
    "    return transcipt_path\n",
    "\n",
    "def get_transcription(episode):\n",
    "    with open(get_path(episode), 'r') as f:\n",
    "        episode_json = json.load(f)\n",
    "        # seems that the last result in each trastcript is a repetition of the first one, so we ignore it\n",
    "        transcripts = [\n",
    "            result[\"alternatives\"][0]['transcript'] if 'transcript' in result[\"alternatives\"][0] else \"\"\n",
    "            for result in episode_json[\"results\"][:-1]\n",
    "        ]\n",
    "        return \" \".join(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What's up, everybody? Welcome to the cycle podcast our very first episode. I'm your host Melissa Boudreaux. I'm so grateful that you're here with us today. Thank you so much for listening. This podcast is going to be centralized around talking about endometriosis, which is an autoimmune disorder that I suffer from for about 20 years now, and I've been wanting to make a podcast because I really do feel there needs to be more awareness and education around this disease. There are other podcasts out there about endometriosis and my idea really for this podcast is to have some informative and educational episodes but also to interview someone different every single month the goal is to have an interview or a podcast every 28 days to go along with the cycle. Hence the name that women have every 28 days. I thought it would be fun. I thought it would be creative and it would give me a way to help spread awareness endometriosis if you don't know about it is a reproduction.  Active disease that mostly affects women a hundred and Seventy-Six million women worldwide. That's about 1 in 10 women 1 in 10 women is a great deal as you know, so helping to bring awareness to this disease is definitely a mission of mine and just something that I feel needs to happen. I think by sharing stories and hearing different perspectives from different women will really help other people and that's really  Ultimate goal of this podcast education and awareness. I really look forward to hearing from you guys. I'd love to hear your feedback and I'm really just grateful that you're actually listening to this if you're listening to it right now. I hope that we can do great things. I hope that we can help other women and we're always open to ideas. So please let us know if you have any ideas or you there's something you would like to see on this podcast. I look forward to publishing another one very very soon something educational and informative.  Formative and then we'll move into some interviews if you have any questions and or concerns, you can always email me at Melissa at booby OU consulting.com, or you can find me on Instagram. Meliss, boo. It's smel is Bo you you can DM me there as well. Thank you again so much for listening. Again. This is just the introduction very very excited to get this going and look forward to more from the cycle coming soon.  Soon. Thanks again. Have a great day.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_idx = 909\n",
    "long_idx = 5211\n",
    "get_transcription(metadata_train.iloc[medium_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hi and welcome to date me or hate me a podcast all about dating The Good the Bad and the Ugly it will all come out here. So let's get into why I'm here today. The reason I actually started this podcast is because I had a few friends coming to me for dating and relationship advice and after hearing the positive feedback that they had for the advice I would Giving them I figured why not give the advice to everyone who might need it. And here we are. So the reason I came up with the name date me or hate me is because me as a person that's kind of how I am. I'm all in like you're going to get me and you either like it or you don't and that's normally how things go. Normally. It's  other guys like how honest I am or they absolutely hate it and that's totally fine as the saying goes. You're not going to be everyone's cup of tea. I'm sure I'm probably someone's cup of bleach somewhere out there. Probably more than one that's for sure. But I will say that that is how I'm going to be on this podcast. I'm going to be unapologetically real and honest with you guys on my experiences your  Variances any and everything that comes up. I'm just going to give you my real honest opinion. You don't have to take my advice. You definitely don't and you probably won't let's be honest, but some of it might be good and some of it you might want to take so I'm just hoping that anyone listening gets a little bit of  something from this  So for this first episode it's going to be strictly the introduction you guys learning about me learning about the podcast learning about what to expect here. I'm hoping to keep the episodes being released on Thursdays for thirsty Thursday too bad. You can't see my like totally corny. Look I'm giving you guys right now. But anyway, I thought it was fitting and so  Let me dive in a little bit on how this podcast is going to work. So the episodes are going to be based on the type of people that you can meet when you are in the dating scene and this comes from talking to one of my friends who also has a podcast. He told me it would be a good idea for the episode naming. So thank you for that. But it also came from my friends for years have been jokingly.  - seriously telling me to write a book about my dating life and I think they more so wanted it so that they could like Laugh at My instances. I've had or circumstances I should say with dating but I've also been the type of person for my friends that they come to when they have dating questions or they need dating advice or even relationship advice. Like I will not say I'm a  ship expert I have had a few and I'm sure we'll get into that on other podcasts but  I am not a relationship expert I would however say that I am pretty close to a dating expert because I have probably dated every single type of guy that you could imagine is out there and I have learned from all these experiences. I like take them with me. I take a little piece of every single date I've ever been on with me.  to be able to help other people who either haven't dated around as much or they're just  just dumped on a situation that they haven't been in before and even when it's an instance that I haven't personally experienced. I've still gotten pretty good feedback from people about my advice to them all so I just realized I said podcast when I meant to say episodes, so I'm totally sorry. I'm still learning the lingo as you can obviously see but  Back to business. So each one is going to be named after someone that you run into while dating but I also want why do I say but so much I'm sorry guys, so it's either butter. So I really need to like pick another transition word. I also want the podcast though, too.  Be something where you get real advice, like I want you guys to either message me or leave me a comment or a voice thing on here. I'm still don't really know how it works. But I want you to ask me questions asked me dating questions that you have and like I said before like you don't have to take my advice if you like get my advice and you're like, oh that's stupid then just don't look.  Listen to me. I mean at the end of the day everyone is going to do what they want to do a hundred percent. That's never going to change. You cannot force anyone to do something. They don't want to do so I could tell you like, oh, yeah kick that guy of the curb girl and you could still go on a date him and he'll maybe even marry him like I'm not saying that my word is Bible like, you know, I sound like a Kardashian. I'm not saying that like you have to a hundred percent take  Advice but if you're curious and if you've been thinking about something that you want someone's feedback on send it to me and I will send you why I won't send you anything. I will go on here and make an episode about it and we could discuss we could like dive in there might be things that like even I haven't dealt with and you guys can help me with so this is going to be very  Like vibey like you're gonna Vibe of me. I'm gonna by both you and we're just going to have a great time. That's what this is all about. Like this is not serious like  It's it's just us talking. Well, mostly me talking because it's a podcast but I want you guys to be involved. I want everyone listening to be involved some way like send me a topic you want me to talk about like we are going to make this into a thing together.  I have to say props to people who do this on the regular because I am having such a hard time not saying but dramatically as you can tell throughout this episode and I just realized I say like so much. It's actually a problem.  I will do better for you guys. I will try my hardest to do better now to dive in a little bit more about me personally. My name is Nicole. I live in Florida now, but I grew up in Virginia. I am a 28 year old female obviously. Well, I guess I shouldn't say obviously it's 2020 and like stranger things have happened. I also recently started my own business.  And I have two part-time jobs. One of them is at a bridal salon, which I know is actually hilarious when you think about me being here talking about dating and not being anywhere remotely close to marriage, but don't get me wrong. I do want to get married one day. I do want to have kids.  That is my however many year plan, but I recently also.  Developed an idea of not trying to control everything and my future and all that stuff. So I'm just kind of going with the flow and it's actually been great. But when I'm not at the bridal salon, I'm at Harley-Davidson doing some promo stuff for them. I do have my motorcycle endorsement. I do not ride around Florida. It freaks me out the drivers here or Horrible no offense, but you guys are and when I'm not working one of my Millions  Jobs that I have I'm hanging out with my friends or with my dog Toto. She's actually here right now. Say hey.  Okay. Thanks for that. So that's a little bit about me and about the podcast and about why I'm here. I'm going to cut this episode a little bit short, since it's just meant to be kind of like a hey, this is what it's going to be and I hope you guys stick around for the other episodes. They're going to be good. I just have a feeling in my bones. And yeah, so I really hope you enjoy I really hope you listen. I really hope you  And in some questions some topics anything at all. I'd love to hear it and I can't wait to see you guys next Thursday PS. I'm really sorry that the quality is kind of a because I'm doing it on my phone because I'm a poor girl, but eventually I will get a official like microphone. So hopefully it'll be better. Love you.  \""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_transcription(metadata_train.iloc[long_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "def look_ahead_chuck(sentences, lower_chunk_size):\n",
    "    \"\"\"\n",
    "    Look-ahead function to determine the next chunk\n",
    "    \"\"\"\n",
    "    if sum([len(s) for s in sentences]) < lower_chunk_size:\n",
    "        return sentences\n",
    "    else:\n",
    "        for i in range(len(sentences)):\n",
    "            if sum([len(s) for s in sentences[:i+1]]) >= lower_chunk_size:\n",
    "                return sentences[:i+1]\n",
    "next_l = [\"I'm really sorry that the quality is kind of a because I'm doing it on my phone because I'm a poor girl, but eventually I will get a official like microphone. \", \"So hopefully it'll be better. \", 'Love you.  ']\n",
    "look_ahead_chuck(next_l, 200)\n",
    "print(sum([len(s) for s in next_l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin([len(get_transcription(metadata_train.iloc[i])) for i in range (20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  29%|██▉       | 128M/438M [00:18<00:18, 17.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27102553844451904 - vs - 0.29411816596984863\n",
      "0.08199809491634369 - vs - 0.20796453952789307\n",
      "0.23852111399173737 - vs - 0.18379461765289307\n",
      "0.24335750937461853 - vs - 0.39189639687538147\n",
      "0.35674217343330383 - vs - 0.3150988221168518\n",
      "0.3809787631034851 - vs - 0.2646925449371338\n",
      "0.17474138736724854 - vs - 0.3235437870025635\n",
      "0.37678059935569763 - vs - 0.46466735005378723\n",
      "0.39269906282424927 - vs - 0.3137981593608856\n",
      "0.5209943056106567 - vs - 0.28821972012519836\n",
      "0.21534693241119385 - vs - 0.16390781104564667\n",
      "0.10270268470048904 - vs - 0.1520935297012329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"I'm Adela Langdon, welcome to impact radio the podcast to reconnect remind Inspire episode 1 ground. \",\n",
       "  'What are the consequences of not being grounded? ',\n",
       "  \"You're not thinking clearly you're not present. \",\n",
       "  \"So, where are you you're on stage giving a presentation you're swaying from side to side you.  \"],\n",
       " [\"Walking around in circles never quite arriving, but you just can't seem to stop it's as if your body has a mind of its own then you forget the most important item in your presentation by now, you're desperate scrambling to find anything to fill in the deafening silence in short you are physically and mentally all over the place. \"],\n",
       " [\"You don't know where you are. \",\n",
       "  \"You're lost.  \",\n",
       "  \"When you feel you are under pressure, your body will always resort to what feels familiar AKA communication habits whether it's working or not. \",\n",
       "  \"You don't have the mental space to get out of this horrible spiral of presentation disasters your presence your connection with your audience is lost.  \"],\n",
       " ['A moment of grounding will give you that mental space. ',\n",
       "  'Remember clear body language clear thinking  What is grounding physically?  ',\n",
       "  'You know where your feet are when you know where you are. ',\n",
       "  'You can think clearly you can respond. ',\n",
       "  \"You can connect here are some of my ground rules ground where you're sitting. \",\n",
       "  'Yes, your feet communicate. '],\n",
       " ['The table does not make you invisible every reactionary twitch or twirl will be felt by you and your audience as a lack of confidence.  '],\n",
       " [\"Oh believability ground when you need to get up so you don't get stuck between the table and chair ground when you are walking to the stage or front of the room so that you can connect with your audience and consciously choose to arrive somewhere ground. \",\n",
       "  \"When you are standing, please move when you're giving a presentation, but give yourself and your  Audience a break move arrived ground connect remember opening statements closing statements strong. \",\n",
       "  \"I believe statement always in the center of the space or stage always grounded your audience won't say gosh. \",\n",
       "  'He looked fabulous me grounded. '],\n",
       " ['No, they will say wow.  ',\n",
       "  'What a great presentation. ',\n",
       "  \"Let's talk grounding is perceived as confidence. \",\n",
       "  'Grounding is heard as Clarity grounding is presence remember?  ',\n",
       "  'clear body language clear thinking ']]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def look_ahead_chuck(sentences, lower_chunk_size):\n",
    "    \"\"\"\n",
    "    Look-ahead function to determine the next chunk\n",
    "    \"\"\"\n",
    "    if sum([len(s) for s in sentences]) < lower_chunk_size:\n",
    "        return sentences\n",
    "    else:\n",
    "        for i in range(len(sentences)):\n",
    "            if sum([len(s) for s in sentences[:i+1]]) >= lower_chunk_size:\n",
    "                return sentences[:i+1]\n",
    "\n",
    "\n",
    "def semantic_segmentation(text, model, lower_chunk_size=300, upper_chunk_size=3000):\n",
    "    \"\"\"\n",
    "    Algorithm proposed by Moro et. al. (2022) to semantically segment long inputs into GPU memory-adaptable chunks.\n",
    "    https://www.aaai.org/AAAI22Papers/AAAI-3882.MoroG.pdf\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    text: str\n",
    "        The text to be segmented\n",
    "    model: SentenceTransformer\n",
    "        The model to be used for the sentence embeddings\n",
    "    lower_chunk_size: int\n",
    "        The lower bound of the chunk size\n",
    "    upper_chunk_size: int\n",
    "        The upper bound of the chunk size\n",
    "    Return\n",
    "    -------\n",
    "    List of chunks of text\n",
    "    \"\"\"\n",
    "\n",
    "    # segment the text into sentences\n",
    "    seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "    sentences = seg.segment(text)\n",
    "\n",
    "    chuncks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    # Iterate over the sentences in the text\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if i == 0:\n",
    "            current_chunk.append(sentence)\n",
    "        elif i == len(sentences) - 1:\n",
    "            # If the sentence is the last one, we add it to the last chunk\n",
    "            current_chunk.append(sentence)\n",
    "            chuncks.append(current_chunk)\n",
    "        elif sum([len(s) for s in current_chunk]) + len(sentence) < lower_chunk_size:\n",
    "            current_chunk.append(sentence)\n",
    "        elif sum([len(s) for s in current_chunk]) + len(sentence) > upper_chunk_size:\n",
    "            chuncks.append(current_chunk)\n",
    "            current_chunk = [sentence]\n",
    "        else:\n",
    "            next_chuck = look_ahead_chuck(sentences[i+1:], lower_chunk_size)\n",
    "            \n",
    "            # get the embedding of the previous chunk and the next chunk\n",
    "            current_embedding = model.encode(current_chunk)\n",
    "            next_embedding = model.encode(next_chuck)\n",
    "            sentence_embedding = model.encode([sentence])\n",
    "\n",
    "            # get the cosine similarity between the embedding of the embeddings\n",
    "            score_current_chunk = util.cos_sim(sentence_embedding, current_embedding).numpy().mean()\n",
    "            score_next_chunk = util.cos_sim(sentence_embedding, next_embedding).numpy().mean()\n",
    "\n",
    "            print(f\"{score_current_chunk} - vs - {score_next_chunk}\")\n",
    "            if score_current_chunk > score_next_chunk:\n",
    "                current_chunk.append(sentence)\n",
    "            else:\n",
    "                chuncks.append(current_chunk)\n",
    "                current_chunk = [sentence]\n",
    "    return chuncks\n",
    "\n",
    "# Initialize the sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "semantic_segmentation(get_transcription(metadata_train.iloc[19]), model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e800dd11dddfb1e3886769e91ed8bbe987a221798b85010fca298ae8afbc389e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
