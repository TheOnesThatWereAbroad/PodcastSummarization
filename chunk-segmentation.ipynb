{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import json\n",
    "import pysbd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.path.abspath(\"\"), 'podcasts-no-audio-13GB')\n",
    "\n",
    "metadata_path_train = os.path.join(dataset_path, 'metadata.tsv')\n",
    "metadata_train = pd.read_csv(metadata_path_train, sep='\\t')\n",
    "\n",
    "def get_path(episode):\n",
    "    # extract the 2 reference number/letter to access the episode transcript\n",
    "    show_filename = episode['show_filename_prefix']\n",
    "    episode_filename = episode['episode_filename_prefix'] + \".json\"\n",
    "    dir_1, dir_2 = re.match(r'show_(\\d)(\\w).*', show_filename).groups()\n",
    "\n",
    "    # check if the transcript file in all the derived subfolders exist\n",
    "    transcipt_path = os.path.join(dataset_path, \"spotify-podcasts-2020\",\n",
    "                                \"podcasts-transcripts\", dir_1, dir_2,\n",
    "                                show_filename, episode_filename)\n",
    "\n",
    "    return transcipt_path\n",
    "\n",
    "def get_transcription(episode):\n",
    "    with open(get_path(episode), 'r') as f:\n",
    "        episode_json = json.load(f)\n",
    "        # seems that the last result in each trastcript is a repetition of the first one, so we ignore it\n",
    "        transcripts = [\n",
    "            result[\"alternatives\"][0]['transcript'] if 'transcript' in result[\"alternatives\"][0] else \"\"\n",
    "            for result in episode_json[\"results\"][:-1]\n",
    "        ]\n",
    "        return \" \".join(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What's up, everybody? Welcome to the cycle podcast our very first episode. I'm your host Melissa Boudreaux. I'm so grateful that you're here with us today. Thank you so much for listening. This podcast is going to be centralized around talking about endometriosis, which is an autoimmune disorder that I suffer from for about 20 years now, and I've been wanting to make a podcast because I really do feel there needs to be more awareness and education around this disease. There are other podcasts out there about endometriosis and my idea really for this podcast is to have some informative and educational episodes but also to interview someone different every single month the goal is to have an interview or a podcast every 28 days to go along with the cycle. Hence the name that women have every 28 days. I thought it would be fun. I thought it would be creative and it would give me a way to help spread awareness endometriosis if you don't know about it is a reproduction.  Active disease that mostly affects women a hundred and Seventy-Six million women worldwide. That's about 1 in 10 women 1 in 10 women is a great deal as you know, so helping to bring awareness to this disease is definitely a mission of mine and just something that I feel needs to happen. I think by sharing stories and hearing different perspectives from different women will really help other people and that's really  Ultimate goal of this podcast education and awareness. I really look forward to hearing from you guys. I'd love to hear your feedback and I'm really just grateful that you're actually listening to this if you're listening to it right now. I hope that we can do great things. I hope that we can help other women and we're always open to ideas. So please let us know if you have any ideas or you there's something you would like to see on this podcast. I look forward to publishing another one very very soon something educational and informative.  Formative and then we'll move into some interviews if you have any questions and or concerns, you can always email me at Melissa at booby OU consulting.com, or you can find me on Instagram. Meliss, boo. It's smel is Bo you you can DM me there as well. Thank you again so much for listening. Again. This is just the introduction very very excited to get this going and look forward to more from the cycle coming soon.  Soon. Thanks again. Have a great day.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_idx = 909\n",
    "long_idx = 5211\n",
    "get_transcription(metadata_train.iloc[medium_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"What's up, everybody? \",\n",
       "  'Welcome to the cycle podcast our very first episode. ',\n",
       "  \"I'm your host Melissa Boudreaux. \",\n",
       "  \"I'm so grateful that you're here with us today. \",\n",
       "  'Thank you so much for listening. ',\n",
       "  \"This podcast is going to be centralized around talking about endometriosis, which is an autoimmune disorder that I suffer from for about 20 years now, and I've been wanting to make a podcast because I really do feel there needs to be more awareness and education around this disease. \",\n",
       "  'There are other podcasts out there about endometriosis and my idea really for this podcast is to have some informative and educational episodes but also to interview someone different every single month the goal is to have an interview or a podcast every 28 days to go along with the cycle. '],\n",
       " ['Hence the name that women have every 28 days. ',\n",
       "  'I thought it would be fun. ',\n",
       "  \"I thought it would be creative and it would give me a way to help spread awareness endometriosis if you don't know about it is a reproduction.  \",\n",
       "  'Active disease that mostly affects women a hundred and Seventy-Six million women worldwide. ',\n",
       "  \"That's about 1 in 10 women 1 in 10 women is a great deal as you know, so helping to bring awareness to this disease is definitely a mission of mine and just something that I feel needs to happen. \"],\n",
       " [\"I think by sharing stories and hearing different perspectives from different women will really help other people and that's really  Ultimate goal of this podcast education and awareness. \",\n",
       "  'I really look forward to hearing from you guys. ',\n",
       "  \"I'd love to hear your feedback and I'm really just grateful that you're actually listening to this if you're listening to it right now. \"],\n",
       " ['I hope that we can do great things. ',\n",
       "  \"I hope that we can help other women and we're always open to ideas. \",\n",
       "  \"So please let us know if you have any ideas or you there's something you would like to see on this podcast. \",\n",
       "  'I look forward to publishing another one very very soon something educational and informative.  ',\n",
       "  \"Formative and then we'll move into some interviews if you have any questions and or concerns, you can always email me at Melissa at booby OU consulting.com, or you can find me on Instagram. \"],\n",
       " ['Meliss, boo. ',\n",
       "  \"It's smel is Bo you you can DM me there as well. \",\n",
       "  'Thank you again so much for listening. ',\n",
       "  'Again. ',\n",
       "  'This is just the introduction very very excited to get this going and look forward to more from the cycle coming soon.  ',\n",
       "  'Soon. ',\n",
       "  'Thanks again. ',\n",
       "  'Have a great day.']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def look_ahead_chuck(sentences, lower_chunk_size):\n",
    "    \"\"\"\n",
    "    Look-ahead function to determine the next chunk\n",
    "    \"\"\"\n",
    "    if sum([len(s) for s in sentences]) < lower_chunk_size:\n",
    "        # if the remaining sentences size is smaller than the lower bound, we return the remaining sentences\n",
    "        return sentences\n",
    "    else:\n",
    "        # next chunk size should be at least the lower bound \n",
    "        for i in range(len(sentences)):\n",
    "            if sum([len(s) for s in sentences[:i+1]]) >= lower_chunk_size:\n",
    "                return sentences[:i+1]\n",
    "\n",
    "\n",
    "def semantic_segmentation(text, model, lower_chunk_size=300, upper_chunk_size=2000):\n",
    "    \"\"\"\n",
    "    Algorithm proposed by Moro et. al. (2022) to semantically segment long inputs into GPU memory-adaptable chunks.\n",
    "    https://www.aaai.org/AAAI22Papers/AAAI-3882.MoroG.pdf\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    text: str\n",
    "        The text to be segmented\n",
    "    model: SentenceTransformer\n",
    "        The model to be used for the sentence embeddings\n",
    "    lower_chunk_size: int\n",
    "        The lower bound of the chunk size\n",
    "    upper_chunk_size: int\n",
    "        The upper bound of the chunk size\n",
    "    Return\n",
    "    -------\n",
    "    List of chunks of text\n",
    "    \"\"\"\n",
    "\n",
    "    # segment the text into sentences\n",
    "    seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "    sentences = seg.segment(text)\n",
    "\n",
    "    chuncks = []\n",
    "    current_chunk = [sentences[0]]\n",
    "\n",
    "    # Iterate over the sentences in the text\n",
    "    for i, sentence in enumerate(sentences[1:]):\n",
    "        if sentence == sentences[-1]:\n",
    "            # If the sentence is the last one, we add it to the last chunk\n",
    "            current_chunk.append(sentence)\n",
    "            chuncks.append(current_chunk)\n",
    "        elif sum([len(s) for s in current_chunk]) + len(sentence) < lower_chunk_size:\n",
    "            # standardize each chunk to a minimum size to best leverage the capability of Transformers\n",
    "            current_chunk.append(sentence)\n",
    "        elif sum([len(s) for s in current_chunk]) + len(sentence) > upper_chunk_size:\n",
    "            # if the chunk is too big, we add it to the list of chunks and start a new one\n",
    "            chuncks.append(current_chunk)\n",
    "            current_chunk = [sentence]\n",
    "        else:\n",
    "            idx = i+1\n",
    "            next_chuck = look_ahead_chuck(sentences[idx+1:], lower_chunk_size)\n",
    "            \n",
    "            # get the embedding of the previous chunk and the next chunk\n",
    "            current_embedding = model.encode(current_chunk)\n",
    "            next_embedding = model.encode(next_chuck)\n",
    "            sentence_embedding = model.encode([sentence])\n",
    "\n",
    "            # get the cosine similarity between the embedding of the embeddings\n",
    "            score_current_chunk = util.cos_sim(sentence_embedding, current_embedding).numpy().mean()\n",
    "            score_next_chunk = util.cos_sim(sentence_embedding, next_embedding).numpy().mean()\n",
    "\n",
    "            # if the score_current_chunk is higher than the score_next_chunk, we add the sentence to the current chunk\n",
    "            if score_current_chunk > score_next_chunk:\n",
    "                current_chunk.append(sentence)\n",
    "            else:\n",
    "                if sum([len(s) for s in current_chunk]) >= lower_chunk_size:\n",
    "                    chuncks.append(current_chunk)\n",
    "                    current_chunk = [sentence]\n",
    "                else:\n",
    "                    current_chunk.append(sentence)\n",
    "    return chuncks\n",
    "\n",
    "# Initialize the sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "semantic_segmentation(get_transcription(metadata_train.iloc[medium_idx]), model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e800dd11dddfb1e3886769e91ed8bbe987a221798b85010fca298ae8afbc389e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
