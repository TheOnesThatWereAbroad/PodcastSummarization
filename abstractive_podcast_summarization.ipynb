{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Abstractive Summarization of Podcast Transcripts with BART using Semantic Self-segmentation\n",
    "Podcasts are a rapidly growing medium for news, commentary, entertainment, and learning.  Some podcast shows release new episodes on a regular schedule (daily, weekly, etc); others irregularly.  Some podcast shows feature short episodes of 5 minutes or less touching on one or two topics; others may release 3+ hour long episodes touching on a wide range of topics.  Some are structured as news delivery, some as conversations, some as storytelling.\n",
    "\n",
    "**Goal**: given a podcast episode, its audio, and transcription, return a short text snippet capturing the most important information in the content. Returned summaries should be grammatical, standalone statement of significantly shorter length than the input episode description.\n",
    "\n",
    "The task is to provide a short text summary that the user might read when deciding whether to listen to a podcast. Thus the summary should accurately convey the content of the podcast, and be short enough to quickly read on a smartphone screen. It should also be human-readable.\n",
    "\n",
    "For further information about the challenge, take a look to Podcasts Track Guidelines:\n",
    "- [TREC 2020 Podcasts Track](https://trecpodcasts.github.io/participant-instructions-2020.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\peppe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import pysbd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AdamWeightDecay\n",
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "import evaluate\n",
    "import bert_score\n",
    "\n",
    "from transcript_utils import get_transcription, semantic_segmentation, extract_features\n",
    "\n",
    "# Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n",
    "tqdm.pandas()\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /root/.huggingface/token\n",
      "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# login to the huggingface hub, necessary only to push the fine-tuned model to the hub\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  Index(['show_uri', 'show_name', 'show_description', 'publisher', 'language',\n",
      "       'rss_link', 'episode_uri', 'episode_name', 'episode_description',\n",
      "       'duration', 'show_filename_prefix', 'episode_filename_prefix'],\n",
      "      dtype='object')\n",
      "Shape:  (105360, 12)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.path.abspath(\"\"), 'podcasts-no-audio-13GB')\n",
    "\n",
    "metadata_path_train = os.path.join(dataset_path, 'metadata.tsv')\n",
    "metadata_train = pd.read_csv(metadata_path_train, sep='\\t')\n",
    "print(\"Columns: \", metadata_train.columns)\n",
    "print(\"Shape: \", metadata_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics about episode duration:\n",
      "count    105360.000000\n",
      "mean         33.845715\n",
      "std          22.735674\n",
      "min           0.175317\n",
      "25%          13.552638\n",
      "50%          31.643375\n",
      "75%          50.446825\n",
      "max         304.953900\n",
      "Name: duration, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Statistics about episode duration:\\n\"\n",
    "      f\"{metadata_train['duration'].describe()}\")\n",
    "metadata_train['duration'].hist(bins=1000, figsize=(10,5), log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics about number of episodes per show:\n",
      "count    18376.000000\n",
      "mean         5.733566\n",
      "std         19.310585\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max       1072.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_episodes = metadata_train.groupby(['show_filename_prefix']).apply(lambda x: list(zip(x['episode_filename_prefix'], x['episode_description']))).to_dict()\n",
    "show_n_episodes = {k: len(v) for k, v in show_episodes.items()}\n",
    "print(\"Statistics about number of episodes per show:\\n\"\n",
    "      f\"{pd.Series(show_n_episodes.values()).describe()}\")\n",
    "pd.Series(show_n_episodes.values()).hist(bins=1000, figsize=(10,5), log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Episode description cleaning\n",
    "\n",
    "First of all, some of the episodes contain a `NaN` value in the `episode_description` and `show_description` columns. Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping NaN values: \n",
      " show_uri                   False\n",
      "show_name                  False\n",
      "show_description            True\n",
      "publisher                  False\n",
      "language                   False\n",
      "rss_link                   False\n",
      "episode_uri                False\n",
      "episode_name               False\n",
      "episode_description         True\n",
      "duration                   False\n",
      "show_filename_prefix       False\n",
      "episode_filename_prefix    False\n",
      "dtype: bool\n",
      "\n",
      "After dropping NaN values:\n",
      " show_uri                   False\n",
      "show_name                  False\n",
      "show_description           False\n",
      "publisher                  False\n",
      "language                   False\n",
      "rss_link                   False\n",
      "episode_uri                False\n",
      "episode_name               False\n",
      "episode_description        False\n",
      "duration                   False\n",
      "show_filename_prefix       False\n",
      "episode_filename_prefix    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"Before dropping NaN values: \\n\", metadata_train.isna().any())\n",
    "metadata_train.dropna(subset=['episode_description', 'show_description'], inplace=True)\n",
    "print(\"\\nAfter dropping NaN values:\\n\", metadata_train.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also available a *gold dataset* of 150 episodes composed by 6 set of summaries for each episode (900 document-summary-grade triplets) that were graded on the Bad/Fair/Good/Excellent scale (0-3).\n",
    "Before starting the cleaning process, we merged this gold dataset with the dataset we are going to clean, and the best summary of each episode will be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path_gold = os.path.join(dataset_path, '150gold.tsv')\n",
    "metadata_gold = pd.read_csv(metadata_path_gold, sep='\\t')\n",
    "\n",
    "quality = {\n",
    "    'B': 1,\n",
    "    'F': 2,\n",
    "    'G': 3,\n",
    "    'E': 4\n",
    "}\n",
    "\n",
    "# convert egfb columns to a quality score\n",
    "egfb_columns = ['EGFB', 'EGFB.1', 'EGFB.2', 'EGFB.3', 'EGFB.4', 'EGFB.5']\n",
    "egfb_to_quality = metadata_gold[egfb_columns].applymap(lambda x: quality[x])\n",
    "\n",
    "# remove rows with no quality > 1\n",
    "egfb_to_quality = egfb_to_quality[[any(row > 1) for row in egfb_to_quality.values]] \n",
    "\n",
    "# select the best transcript for each episode\n",
    "best_egfb = egfb_to_quality.apply(lambda x: x.idxmax(), axis=1)\n",
    "best_summary = [metadata_gold.iloc[i, np.argwhere(metadata_gold.columns == egfb)[0][0] - 1] for i, egfb in best_egfb.iteritems()]\n",
    "\n",
    "metadata_gold = metadata_gold.loc[best_egfb.index]\n",
    "metadata_gold['best_summary'] = best_summary\n",
    "\n",
    "# create a dictionary of the best summary for each episode\n",
    "gold_summaries = {row['episode id']: row['best_summary'] for i, row in metadata_gold.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute the episode descriptions correspondent to the episodes in the gold set with the best summary\n",
    "for i, row in metadata_train.iterrows():\n",
    "    if row['episode_uri'] in gold_summaries.keys():\n",
    "        metadata_train.at[i, 'episode_description'] = gold_summaries[row['episode_uri']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We strive to enhance the quality of creator descriptions using heuristics. In order to do that, the following cleaning steps are preformed:\n",
    "- removing the content after \"---\" that usually is a sponsorship or a boilerplate (e.g., *“--- This episode is sponsored by ...”* *“--- Send in a voice message”*)\n",
    "- remove sentences that contain URLs, @mentions and email addresses in the episode descriptions\n",
    "- remove tokens corresponding to emojii\n",
    "- identify sentences that contain not useful content and remove them from the descriptions. In order to do that, we compute a *salience score* for each sentence of the description by summing over word IDF scores. Then we remove sentences if their salience scores are lower than a threshold. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing word frequencies: 100%|██████████| 105153/105153 [07:58<00:00, 219.77it/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_document_frequencies(descriptions):\n",
    "    \"\"\"\n",
    "    Compute the document frequencies in the whole dataset descriptions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    descriptions : list of str\n",
    "        The descriptions of the episodes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary of word frequencies\n",
    "    \"\"\"\n",
    "    seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "\n",
    "    # get a set of words contained in each description (words are all lowercase)\n",
    "    flattened_descriptions = []\n",
    "    for description in tqdm(descriptions, desc=\"Computing word frequencies\"):\n",
    "        description_set = set()\n",
    "        for sentence in seg.segment(description):\n",
    "            description_set.update([word.lower() for word in word_tokenize(sentence)])\n",
    "        flattened_descriptions.extend(list(description_set))\n",
    "            \n",
    "    counts = pd.Series(Counter(flattened_descriptions))  # Get counts and transform to Series\n",
    "    return counts\n",
    "\n",
    "# compute the document frequencies that will be used to compute the sentence salience score\n",
    "document_frequencies = compute_document_frequencies(metadata_train['episode_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the old dataframe to make comparisons\n",
    "metadata_train_old = metadata_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing boilerplate from the episode descriptions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105153/105153 [00:00<00:00, 120642.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing links and sponsors from the episode descriptions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105153/105153 [06:19<00:00, 276.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing emojii from the episode descriptions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105153/105153 [00:00<00:00, 124739.31it/s]\n"
     ]
    }
   ],
   "source": [
    "def remove_boilerplate(description):\n",
    "    \"\"\"\n",
    "    Remove boilerplate from the episode description\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    description : str\n",
    "        The episode description\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A description without boilerplate (str)\n",
    "    \"\"\"\n",
    "    boilerplate_re = re.compile(r\"---.*\")\n",
    "    return boilerplate_re.sub(\"\", description)\n",
    "\n",
    "def remove_link_or_sponsors(description):\n",
    "    \"\"\"\n",
    "    Remove sentences containing links and sponsors or username and hashtag from the episode description\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    description : str\n",
    "        The episode description\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A description without links and sponsors (str)\n",
    "    \"\"\"\n",
    "    username_and_hashtag_re = re.compile(r\"(\\B@\\w+|\\B#\\w+)\")\n",
    "    links_or_sponsors_re = re.compile(\n",
    "        r\"(http|https|[pP]atreon|[eE]mail|[dD]onate|IG|[iI]nstagram|[fF]acebook|[yY]outube|[tT]witter|[dD]iscord|[fF]ollow|[sS]potify)\"\n",
    "    )\n",
    "\n",
    "    # remove username and hashtag\n",
    "    description = username_and_hashtag_re.sub(\" \", description)\n",
    "\n",
    "    # remove sentences containing links and sponsors\n",
    "    seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "    sentences = seg.segment(description)\n",
    "    sentences = [sentence for sentence in sentences if not links_or_sponsors_re.search(sentence)] \n",
    "    return \" \".join(sentences)\n",
    "\n",
    "def remove_emojii(description):\n",
    "    \"\"\"\n",
    "    Remove emojii from the episode description\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    description : str\n",
    "        The episode description\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A description without emojii (str)\n",
    "    \"\"\"\n",
    "    emoji_re = re.compile(r\"[^\\x00-\\x7F]+\")\n",
    "    return emoji_re.sub(\" \", description)\n",
    "\n",
    "print(\"\\nRemoving boilerplate from the episode descriptions:\")\n",
    "metadata_train['episode_description'] = metadata_train['episode_description'].progress_map(remove_boilerplate)\n",
    "\n",
    "print(\"Removing links and sponsors from the episode descriptions:\")\n",
    "metadata_train['episode_description'] = metadata_train['episode_description'].progress_map(remove_link_or_sponsors)\n",
    "\n",
    "print(\"Removing emojii from the episode descriptions:\")\n",
    "metadata_train['episode_description'] = metadata_train['episode_description'].progress_map(remove_emojii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of comparisons before and after removing sponsors and links:\n",
      "BEFORE:\n",
      "\t- If you like ASMR you will love this White Noise Machine on Amazon! Tap here to check it out! If you enjoyed this make sure to give us a 5 star rating!  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/AdamDino/support\n",
      "AFTER:\n",
      "\t- If you like ASMR you will love this White Noise Machine on Amazon!  Tap here to check it out!  If you enjoyed this make sure to give us a 5 star rating!  \n",
      "\n",
      "\n",
      "BEFORE:\n",
      "\t- Danielle and Jessi could talk your ears off when it comes to this topic. Episode 004 is all about their skincare routines, products they love, and tips and tricks for feeling radiant and confident in your own skin. Follow them @basicallyorganicpodcast (and @jessimechler @itsdaniellebridges) for tags of all the brands they’re currently loving! Rate and subscribe!!   ---   Support this podcast: https://anchor.fm/basicallyorganicpodcast/support\n",
      "AFTER:\n",
      "\t- Danielle and Jessi could talk your ears off when it comes to this topic.  Episode 004 is all about their skincare routines, products they love, and tips and tricks for feeling radiant and confident in your own skin.  Rate and subscribe!!   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see a few examples of comparisons between the old and new descriptions\n",
    "samples = [137, 172]\n",
    "print(\"\\nExamples of comparisons before and after removing sponsors and links:\")\n",
    "for i in samples:\n",
    "        print(\"BEFORE:\" \n",
    "                f\"\\n\\t- {metadata_train_old['episode_description'].iloc[i]}\")\n",
    "        print(\"AFTER:\"\n",
    "                f\"\\n\\t- {metadata_train['episode_description'].iloc[i]}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105153/105153 [24:23<00:00, 71.84it/s] \n"
     ]
    }
   ],
   "source": [
    "def sentence_salience_score(sentence, num_descriptions, document_frequencies):\n",
    "    \"\"\"\n",
    "    Compute the salience score of a sentence by summing over word IDF scores.\n",
    "    Only alphabetic words that are longer that one character and are neither stop words nor words like 'episode' or 'podcast'\n",
    "    are considered when computing sentence salience scores.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        The sentence to compute the salience score for\n",
    "    num_descriptions : int\n",
    "        The number of descriptions in the dataset\n",
    "    document_frequencies : pandas.Series\n",
    "        The document frequencies in the whole dataset descriptions\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The salience score of the sentence (float)\n",
    "    \"\"\"\n",
    "    idf_scores = []\n",
    "    tokenized_sentence = word_tokenize(sentence)\n",
    "\n",
    "    # compute IDF scores for each word in the sentence and sum them up \n",
    "    \n",
    "    for word in tokenized_sentence:\n",
    "        lower_world = word.lower()\n",
    "        # consider only alphabetic words, and remove stop words, single character\n",
    "        if lower_world in document_frequencies.keys() and lower_world.isalpha() and lower_world not in stopwords.words('english') and len(lower_world) > 1 and lower_world not in ['episode', 'podcast']:\n",
    "            # get document frequency\n",
    "            df = document_frequencies[lower_world]\n",
    "\n",
    "            # compute idf score\n",
    "            idf_score = np.log(num_descriptions/df)\n",
    "            idf_scores.append(idf_score)\n",
    "\n",
    "    idf_scores = np.array(idf_scores) \n",
    "    salience_score = idf_scores.mean() if len(idf_scores)>0 else 0.0\n",
    "    return salience_score\n",
    "\n",
    "def remove_unuseful_sentences(description, num_descriptions, word_frequencies, threshold=3.6):\n",
    "    \"\"\"\n",
    "    Remove sentences that are not useful for the transcriptions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    description : str\n",
    "        The episode description\n",
    "    num_descriptions : int\n",
    "        The number of descriptions in the dataset\n",
    "    word_frequencies : pandas.Series\n",
    "        The word frequencies in the whole dataset descriptions\n",
    "    threshold : double\n",
    "        The threshold for the salience score of a sentence to be considered useful\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A description without unuseful sentences (str)\n",
    "    \"\"\"\n",
    "    # segment the text into sentences\n",
    "    seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "    sentences = seg.segment(description)\n",
    "    # remove sentences that are not useful for the transcriptions\n",
    "    sentences = [sentence for sentence in sentences if sentence_salience_score(sentence, num_descriptions, word_frequencies) > threshold]\n",
    "    return \" \".join(sentences)\n",
    "\n",
    "metadata_train['episode_description'] = metadata_train['episode_description'].progress_map(lambda x: remove_unuseful_sentences(x, metadata_train.shape[0], document_frequencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of comparisons before and after removing sponsors and links:\n",
      "BEFORE:\n",
      "\t- If you like ASMR you will love this White Noise Machine on Amazon! Tap here to check it out! If you enjoyed this make sure to give us a 5 star rating!  ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/AdamDino/support\n",
      "AFTER:\n",
      "\t- If you like ASMR you will love this White Noise Machine on Amazon!   Tap here to check it out!  \n",
      "\n",
      "\n",
      "BEFORE:\n",
      "\t- Danielle and Jessi could talk your ears off when it comes to this topic. Episode 004 is all about their skincare routines, products they love, and tips and tricks for feeling radiant and confident in your own skin. Follow them @basicallyorganicpodcast (and @jessimechler @itsdaniellebridges) for tags of all the brands they’re currently loving! Rate and subscribe!!   ---   Support this podcast: https://anchor.fm/basicallyorganicpodcast/support\n",
      "AFTER:\n",
      "\t- Danielle and Jessi could talk your ears off when it comes to this topic.   Episode 004 is all about their skincare routines, products they love, and tips and tricks for feeling radiant and confident in your own skin.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see a few examples of comparisons between the old and new descriptions\n",
    "samples = [137, 172]\n",
    "print(\"\\nExamples of comparisons before and after removing unuseful sentences:\")\n",
    "for i in samples:\n",
    "        print(\"BEFORE:\" \n",
    "                f\"\\n\\t- {metadata_train_old['episode_description'].iloc[i]}\")\n",
    "        print(\"AFTER:\"\n",
    "                f\"\\n\\t- {metadata_train['episode_description'].iloc[i]}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Episode selection\n",
    "In order to select a subset of the training set that is proper to achieve good summarization results, we filtered out some descriptions using three heuristics shown in the table below. These filters overlap to some extent, and remove about a third of the entire set. The remaining episodes we call the **Brass Set**.\n",
    "\n",
    "| Criterion                        | Threshold                                                    |\n",
    "| -------------------------------- | ------------------------------------------------------------ |\n",
    "| Length                           | descriptions that are very long (> 750 characters) or short (< 20 characters). |\n",
    "| Similarity to show description   | descriptions with high lexical overlap (over 50%) with their show description. |\n",
    "| Similarity to other descriptions | descriptions with high lexical overlap (over 60%) with other episode descriptions in the same show. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105153/105153 [00:01<00:00, 77508.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 17108 episodes (16.27%) because of too long or too short descriptions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88045/88045 [01:16<00:00, 1157.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1597 episodes (1.81%) because of too high overlap with the show description\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86448/86448 [41:22<00:00, 34.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 9033 episodes (10.45%) because of too high overlap with other descriptions in the same show\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def check_lenght_brass(episode, upper_bound=750, lower_bound=20):\n",
    "    \"\"\"\n",
    "    Check if the episode descriptions is not too long (> 750 characters) or not too short (< 20 characters)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : pandas.Series\n",
    "        A row from the metadata file\n",
    "    upper_bound : int\n",
    "        The upper bound of the episode description length\n",
    "    lower_bound : int\n",
    "        The lower bound of the episode description length\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Boolean indicating if the episode description is long enough\n",
    "    \"\"\"\n",
    "    return len(episode['episode_description']) <= upper_bound and len(episode['episode_description']) >= lower_bound\n",
    "    \n",
    "def description_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Measure the overlapping between two descriptions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : str\n",
    "        The first description\n",
    "    b : str\n",
    "        The second description\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Value indicating the overlapping between the two descriptions\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def check_show_description_overlap_brass(episode, thresh=0.5):\n",
    "    \"\"\"\n",
    "    Check if the episode descriptions overlapping with the show description is not too high (< 0.5)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : pandas.Series\n",
    "        A row from the metadata file\n",
    "    thresh : float\n",
    "        The threshold of the overlap between the episode description and the show description\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Boolean indicating if the episode description is different enough from the show description\n",
    "    \"\"\"\n",
    "    return description_similarity(episode['show_description'], episode['episode_description']) < thresh\n",
    "    \n",
    "def check_other_description_overlap_brass(episode, show_episodes, thresh=0.6):\n",
    "    \"\"\"\n",
    "    Check if the episode descriptions overlapping with the other description in the same show is not too high (< 0.6)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : pandas.Series\n",
    "        A row from the metadata file\n",
    "    show_episodes : dict\n",
    "        A dictionary of the episodes of the same show\n",
    "    thresh : float\n",
    "        The threshold of the overlap between the episode description and the other description\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Boolean indicating if the episode description is different enough from the other description\n",
    "    \"\"\"\n",
    "    for other_prefix, other_description in show_episodes[episode['show_filename_prefix']]:\n",
    "        if other_prefix != episode['episode_filename_prefix'] and description_similarity(episode['episode_description'], other_description) > thresh and len(episode['episode_description']) < len(other_description):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "brass_set_lenght = metadata_train[metadata_train.progress_apply(check_lenght_brass, axis=1)]\n",
    "print(f\"Removed {len(metadata_train) - len(brass_set_lenght)} episodes ({(100-(len(brass_set_lenght)/len(metadata_train)*100)):.2f}%) because of too long or too short descriptions\")\n",
    "\n",
    "brass_set_show_overlap = brass_set_lenght[brass_set_lenght.progress_apply(check_show_description_overlap_brass, axis=1)]\n",
    "print(f\"Removed {len(brass_set_lenght) - len(brass_set_show_overlap)} episodes ({(100-(len(brass_set_show_overlap)/len(brass_set_lenght)*100)):.2f}%) because of too high overlap with the show description\")\n",
    "\n",
    "show_episodes = brass_set_show_overlap.groupby(['show_filename_prefix']).apply(lambda x: list(zip(x['episode_filename_prefix'], x['episode_description']))).to_dict()\n",
    "brass_set = brass_set_show_overlap[brass_set_show_overlap.progress_apply(lambda x: check_other_description_overlap_brass(x, show_episodes), axis=1)]\n",
    "print(f\"Removed {len(brass_set_show_overlap) - len(brass_set)} episodes ({(100-(len(brass_set)/len(brass_set_show_overlap)*100)):.2f}%) because of too high overlap with other descriptions in the same show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode description: \n",
      "\tLife and fashion all packed into a panini \n",
      "Show description: \n",
      "\tLife and fashion all packed into a panini\n",
      "Overlapping score: \n",
      "\t0.9879518072289156\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tToday, three of the worlds straightest males have gathered to talk about the straightest things. \n",
      "Show description: \n",
      "\tOn the Wearings-Socks Podcast, three of the worlds straightest males have gathered to talk about the straightest things.\n",
      "Overlapping score: \n",
      "\t0.8663594470046083\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tWe look back at the case of the Maryland Court vs Adnan Syed and tell you what we think really happened on that fateful day in 1999 \n",
      "Show description: \n",
      "\tWe're out here doing a podcast about the Serial Podcast that is based off of the State of Maryland v. Adnan Syed case that happened back in 1999.\n",
      "Overlapping score: \n",
      "\t0.51985559566787\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look to the removed episode descriptions due to the overlap with the show description\n",
    "removed_episodes_show_overlap = pd.concat([brass_set_lenght, brass_set_show_overlap]).drop_duplicates(keep=False)[['show_description', 'episode_description']]\n",
    "removed_episodes_show_overlap['overlapping'] = removed_episodes_show_overlap.apply(lambda row: description_similarity(row['show_description'], row['episode_description']), axis=1)\n",
    "\n",
    "num_to_visualize = 3\n",
    "\n",
    "for _ in range(num_to_visualize):\n",
    "    row = removed_episodes_show_overlap.sample()\n",
    "    print(f\"Episode description: \\n\\t{row['episode_description'].values[0]}\")\n",
    "    print(f\"Show description: \\n\\t{row['show_description'].values[0]}\")\n",
    "    print(f\"Overlapping score: \\n\\t{row['overlapping'].values[0]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode description: \n",
      "\tA real banger, one for the ages  \n",
      "Other episode description: \n",
      "\tThis is a banger, one for the ages  \n",
      "Overlapping score: \n",
      "\t0.8405797101449275\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tIn this exercise, drift off to sleep while listening to nature sounds. \n",
      "Other episode description: \n",
      "\tIn the full version of this exercise, focus on muscle relaxation while listening to nature sounds. \n",
      "Overlapping score: \n",
      "\t0.7176470588235294\n",
      "\n",
      "\n",
      "Episode description: \n",
      "\tIn this episode, Shawna and Larry talk with Jason Lobmeyer about helpful tips on how to be a great CCV kids coach. \n",
      "Other episode description: \n",
      "\tIn this episode, Shawna and Larry talk with George Mang about helpful tips on how deal with behavioral issues in a kids experience. \n",
      "Overlapping score: \n",
      "\t0.7125506072874493\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look to the removed episode descriptions due to the overlap with the other episode descriptions in the same show\n",
    "removed_episodes_other_overlap = pd.concat([brass_set, brass_set_show_overlap]).drop_duplicates(keep=False)[['show_filename_prefix', 'episode_filename_prefix', 'episode_description']]\n",
    "two_episodes_show  = {str(show_filename_prefix): show_episodes[show_filename_prefix] for show_filename_prefix in removed_episodes_other_overlap['show_filename_prefix'] if len(show_episodes[show_filename_prefix]) == 2 }\n",
    "removed_episodes_other_overlap = removed_episodes_other_overlap[removed_episodes_other_overlap['show_filename_prefix'].isin(two_episodes_show.keys())]\n",
    "other_episode_show = {}\n",
    "for i, row in removed_episodes_other_overlap.iterrows():\n",
    "    if row['show_filename_prefix'] in two_episodes_show:\n",
    "        if row['episode_filename_prefix'] in two_episodes_show[row['show_filename_prefix']][0]:\n",
    "            other_episode_show[row['show_filename_prefix']] = two_episodes_show[row['show_filename_prefix']][1][1]\n",
    "        else:\n",
    "            other_episode_show[row['show_filename_prefix']] = two_episodes_show[row['show_filename_prefix']][0][1]\n",
    "removed_episodes_other_overlap['other_episode_description'] = removed_episodes_other_overlap.apply(lambda row: other_episode_show[row['show_filename_prefix']], axis=1)\n",
    "removed_episodes_other_overlap['overlapping'] = removed_episodes_other_overlap.apply(lambda row: description_similarity(row['episode_description'], row['other_episode_description']), axis=1)\n",
    "\n",
    "num_to_visualize = 3\n",
    "\n",
    "for _ in range(num_to_visualize):\n",
    "    row = removed_episodes_other_overlap.sample()\n",
    "    print(f\"Episode description: \\n\\t{row['episode_description'].values[0]}\")\n",
    "    print(f\"Other episode description: \\n\\t{row['other_episode_description'].values[0]}\")\n",
    "    print(f\"Overlapping score: \\n\\t{row['overlapping'].values[0]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Further selection of the data\n",
    "The podcast episodes should be restricted to the English language, but they cover a range of geographical regions and we found a number of non-English podcasts in the dataset. So we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77415/77415 [00:26<00:00, 2925.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 374 episodes (0.48%) because of non english description\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('corpora/words')\n",
    "except LookupError:\n",
    "    nltk.download('words')\n",
    "wordset = set(words.words())\n",
    "\n",
    "def is_english(text, threshold = 0.3):\n",
    "    \"\"\"\n",
    "    Check if the text is written in english\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The text to check\n",
    "    threshold : float\n",
    "        The threshold of the ratio of english words in the text\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Boolean indicating if the text is written in english\n",
    "    \"\"\"\n",
    "    tokenized = word_tokenize(text)\n",
    "    alpha_tokenized = [word.lower() for word in tokenized if word.isalpha()]\n",
    "    dictionary_score = sum([word.lower() in wordset for word in alpha_tokenized\n",
    "                           ]) / len(alpha_tokenized)\n",
    "    return dictionary_score > threshold\n",
    "\n",
    "# remove episodes with non english description\n",
    "len_old_brass_set = len(brass_set)\n",
    "brass_set = brass_set[brass_set.progress_apply(lambda x: is_english(x['episode_description']), axis=1)]\n",
    "print(f\"Removed {len_old_brass_set - len(brass_set)} episodes ({(100-(len(brass_set)/len_old_brass_set*100)):.2f}%) because of non english description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store brass set\n",
    "brass_set.to_csv(os.path.join(os.path.dirname(metadata_path_train), \"brass_set.tsv\"), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Transcript filtering\n",
    "For each episode, extract the chunks from the transcript, classify them to evaluate their salience and take the ones with the highest score up to fulfill 1024 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load brass set\n",
    "brass_set = pd.read_csv(os.path.join(dataset_path, \"brass_set.tsv\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript_filtering(episode, chunk_classifier, sentence_encoder, tokenizer, test_set=False):\n",
    "    \"\"\"\n",
    "    Extract the most salient chunks inside the transcript of an episode\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : pandas.Series\n",
    "        The episode to extract the chunks from\n",
    "    chunk_classifier : tf.Model\n",
    "        The classifier to use to extract the most salient chunks\n",
    "    sentence_encoder : tf.Model\n",
    "        The encoder to use to encode the sentences\n",
    "    tokenizer : AutoTokenizer\n",
    "        The BART tokenizer to use to tokenize the transcript\n",
    "    test_set : Boolean\n",
    "        If True, the trascriptions will be searched in the test set directory, otherwise in the training set directory (default: False)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    Transcript after the selection of the most salient chunks\n",
    "    \"\"\"\n",
    "\n",
    "    # extraction of chunks from the episode\n",
    "    chunks = semantic_segmentation(get_transcription(episode, dataset_path, test_set), sentence_encoder)\n",
    "\n",
    "    # extraction of features for each chunk\n",
    "    features = np.array([extract_features(chunk, sentence_encoder) for chunk in chunks])\n",
    "    \n",
    "    # prediction of the classifier\n",
    "    y = chunk_classifier.predict(features)\n",
    "\n",
    "    # score for each chunk\n",
    "    scores = [{'idx': i, 'relevance':y[i]} for i in range(len(chunks))]\n",
    "\n",
    "    # sorting chunks according to the probability to be relevant\n",
    "    scores.sort(key=lambda e: e['relevance'], reverse=True)\n",
    "\n",
    "    # filter chunks according to a maximum amount of 1024 tokens\n",
    "    count = 0\n",
    "    i = 0\n",
    "    max_tokens = 1024\n",
    "    # until the number of tokens is not max_tokens and there are still chunks to tokenize\n",
    "    while count <= max_tokens and i < len(scores):\n",
    "        count += len(tokenizer(' '.join(chunks[scores[i]['idx']]))['input_ids'])\n",
    "        i += 1\n",
    "    # if total number of chunk is less than max_tokens\n",
    "    if i == len(scores):\n",
    "        relevant_chunks = [' '.join(chunk) for chunk in chunks]\n",
    "    # othewise if there are more token than max_tokens\n",
    "    else:\n",
    "        selected_chunks = {scores[j]['idx']: chunks[scores[j]['idx']] for j in range(i-1)}\n",
    "        # reoreder chunks in the original order\n",
    "        relevant_chunks = [' '.join(chunks[idx]) for idx in sorted(selected_chunks.keys())]\n",
    "\n",
    "    # return the new transcript\n",
    "    return ' '.join(relevant_chunks)\n",
    "\n",
    "\n",
    "chunk_classifier = keras.models.load_model(\"modelChunkNN\")\n",
    "model_checkpoint = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "sentence_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "brass_set['filtered_transcript'] = brass_set.iloc.progress_apply(lambda x: transcript_filtering(x, chunk_classifier, sentence_encoder, tokenizer), axis=1)\n",
    "\n",
    "brass_set[['episode_uri','filtered_transcript', 'episode_description']].to_csv(os.path.join(dataset_path, \"filtered_set.csv\"), index=False)\n",
    "print(\"Filtering done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train/dev split\n",
    "We will use the `Datasets` library from Huggingface to handle the dataset for the training step. This can be easily done with the function `load_dataset`. Then we split the data into train/dev sets of ratio 90%-10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 69336\n",
      "Validation set size: 7705\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files=os.path.join(dataset_path, \"filtered_set.csv\"))\n",
    "\n",
    "train_set, validation_set = dataset['train'].train_test_split(test_size=0.1).values()\n",
    "print(f\"Training set size: {train_set.num_rows}\")\n",
    "print(f\"Validation set size: {validation_set.num_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get the metric we need to use for evaluation (to compare our model to the benchmark) using the `load_metric` function. We use the ROUGE metrc to check the progress of the model during the training on the validation set. At evaluation time, we use more powerful metrics (like BERTScore) to evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing the data\n",
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a Huggingface Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint.\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a function to preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tokenize_preprocess(dataset, text_column, summary_column, tokenizer, max_input_length, max_target_length):\n",
    "    \"\"\"\n",
    "    Preprocess a dataset by tokenizing the transcript and the summary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : Dataset\n",
    "        The dataset to preprocess\n",
    "    text_column : str\n",
    "        The name of the column containing the transcript\n",
    "    summary_column : str\n",
    "        The name of the column containing the summary\n",
    "    tokenizer : AutoTokenizer\n",
    "        The tokenizer to use\n",
    "    max_input_length : int\n",
    "        The maximum length of the input sequence\n",
    "    max_target_length : int\n",
    "        The maximum length of the target sequence\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The preprocessed dataset\n",
    "    \"\"\"\n",
    "    inputs = dataset[text_column]\n",
    "    targets = dataset[summary_column]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our dataset object we created earlier. This will apply the function on all the elements of all the splits in dataset, so our training and validation data will be preprocessed. Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x7f6a5775daf0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537c3027b32c4f1fba8e745de1956b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset:   0%|          | 0/43 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfaf988b0a04d52aa24ba71c6386000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 256\n",
    "\n",
    "\n",
    "train_set_tokenized = train_set.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "        batch, \"filtered_transcript\", \"episode_description\", tokenizer, max_input_length, max_target_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=train_set.column_names,\n",
    "    desc=\"Running tokenizer on train dataset\"\n",
    ")\n",
    "\n",
    "validation_set_tokenized = validation_set.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "        batch, \"filtered_transcript\", \"episode_description\", tokenizer, max_input_length, max_target_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=validation_set.column_names,\n",
    "    desc=\"Running tokenizer on validation dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Fine-tuning the model\n",
    "Now that our data is ready, we can download the pretrained **BART model** and fine-tune it. Since our task is sequence-to-sequence (both the input and output are text sequences), we use the `AutoModelForSeq2SeqLM` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 11:04:55.936049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.936395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.936684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.936968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.940577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.940858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.941133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.941394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.941651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.941907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.942159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.942410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:55.943268: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-16 11:04:56.221802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.222106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.222365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.222625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.222884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.223133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.223380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.223629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.223876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.224125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.224372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:56.224620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.167868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.168202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.168482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.168756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.169018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.169290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.169541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.169792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.170048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.170294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22309 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-06-16 11:04:57.170885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.171112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22309 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2b:00.0, compute capability: 8.6\n",
      "2022-06-16 11:04:57.171316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.171538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22309 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2022-06-16 11:04:57.171817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 11:04:57.172041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22309 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 11:04:58.373403: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# prepare the model\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need a special kind of data collator, which will not only pad the inputs to the maximum length in the batch, but also the labels. Note that data collators are multi-framework, so make sure you set `return_tensors='tf'` so you get `tf.Tensor` objects back and not something else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert our input datasets to TF datasets using this collator. There's a built-in method for this: `to_tf_dataset()`. Make sure to specify the collator we just created as our collate_fn!\n",
    "\n",
    "Computing the ROUGE metric can be slow because it requires the model to generate outputs token-by-token. To speed things up, we make a `generation_dataset` that contains only 200 examples from the validation dataset, and use this for ROUGE computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the training\n",
    "batch_size = 4\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "num_train_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_set_tokenized.to_tf_dataset(\n",
    "    batch_size=batch_size,\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "validation_dataset = validation_set_tokenized.to_tf_dataset(\n",
    "    batch_size=batch_size,\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "generation_dataset = (\n",
    "    validation_set_tokenized\n",
    "    .shuffle()\n",
    "    .select(list(range(200)))\n",
    "    .to_tf_dataset(\n",
    "        batch_size=batch_size,\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize our loss and optimizer and compile the model. Note that most Transformers models compute loss internally - we can train on this as our loss value simply by not specifying a loss when we `compile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train our model. We can also add some callbacks (code adapted from the [huggingface notebook repository](https://github.com/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)):\n",
    "- *TensorBoard* is a built-in Keras callback that logs TensorBoard metrics.\n",
    "- *KerasMetricCallback* is a callback for computing advanced metrics. There are a number of common metrics in NLP like ROUGE which are hard to fit into your compiled training loop because they depend on decoding predictions and labels back to strings with the tokenizer, and calling arbitrary Python functions to compute the metric. The KerasMetricCallback will wrap a metric function, outputting metrics as training progresses.\n",
    "This callback allows complex metrics to be computed each epoch that would not function as a standard Keras Metric. Metric values are printed each epoch, and can be used by other callbacks like TensorBoard or EarlyStopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No label_cols specified for KerasMetricCallback, assuming you want the 'labels' key.\n"
     ]
    }
   ],
   "source": [
    "def metric_fn(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    for label in labels:\n",
    "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_predictions = [\n",
    "        \"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_predictions\n",
    "    ]\n",
    "    decoded_labels = [\n",
    "        \"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels\n",
    "    ]\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_predictions, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    # Add mean generated length\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "model_path = \"bart-large-finetuned/filtered-spotify-podcast-summ\"\n",
    "\n",
    "log_dir = model_path + \"/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn, eval_dataset=generation_dataset, predict_with_generate=True\n",
    ")\n",
    "\n",
    "callbacks = [metric_callback, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "17334/17334 [==============================] - 5956s 554ms/step - loss: 3.0440 - val_loss: 2.8733\n",
      "Epoch 2/3\n",
      "17334/17334 [==============================] - 5921s 554ms/step - loss: 2.6085 - val_loss: 2.8549\n",
      "Epoch 3/3\n",
      "17334/17334 [==============================] - 5913s 553ms/step - loss: 2.2967 - val_loss: 2.8316\n"
     ]
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "history = model.fit(\n",
    "    train_dataset, validation_data=validation_dataset, epochs=num_train_epochs, callbacks=callbacks\n",
    ")\n",
    "history = history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will sync up our model with the Hub. This allows us to resume training from other machines and share the model after training is finished!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_deprecation.py:39: FutureWarning: Pass token='bart-large-finetuned-filtered-spotify-podcast-summ' as keyword args. From version 0.8 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py:673: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/gmurro/bart-large-finetuned-filtered-spotify-podcast-summ into local empty directory.\n",
      "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/gmurro/bart-large-finetuned-filtered-spotify-podcast-summ into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb2b452656f4de6b13dedba0ee41057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file tf_model.h5:   0%|          | 32.0k/1.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/gmurro/bart-large-finetuned-filtered-spotify-podcast-summ\n",
      "   0a75d30..6b7b4f2  main -> main\n",
      "\n",
      "WARNING:huggingface_hub.repository:To https://huggingface.co/gmurro/bart-large-finetuned-filtered-spotify-podcast-summ\n",
      "   0a75d30..6b7b4f2  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/gmurro/bart-large-finetuned-filtered-spotify-podcast-summ/commit/6b7b4f26fe793f79be93bae71d12496afd76cee8'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_model_id = \"bart-large-finetuned-filtered-spotify-podcast-summ\"\n",
    "model.push_to_hub(hub_model_id)\n",
    "tokenizer.push_to_hub(hub_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 History of the fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame: \n",
    "path_model_history = os.path.join(model_path, 'history')\n",
    "if not os.path.exists(path_model_history):\n",
    "    os.makedirs(path_model_history)\n",
    "    \n",
    "df_history = pd.DataFrame(history) \n",
    "with open(os.path.join(path_model_history, \"history.csv\"), mode=\"w\") as file:\n",
    "    df_history.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore history\n",
    "cols = ['loss','val_loss','rouge1', 'rouge2', 'rougeL', 'rougeLsum', 'gen_len']\n",
    "path_model_history = os.path.join(model_path, 'history')\n",
    "history = pd.read_csv(os.path.join(path_model_history, \"history.csv\"), usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(models_history, keys, model_names=[], labels=(\"epochs\", \"metrics\"), y_scale=\"linear\", figsize=(10,5), cmap='rainbow'):\n",
    "    \"\"\"\n",
    "    Plot the history of the metrics in the history dictionary for each model.\n",
    "        :param models_history: array of dictionary of the metric history for each model\n",
    "        :param keys: list of keys of the metrics to plot\n",
    "        :param model_names: list of names of the models\n",
    "        :param labels: list of labels of the axes\n",
    "        :param figsize: size of the figure\n",
    "        :param cmap: color map used for the plot\n",
    "    \"\"\"\n",
    "\n",
    "    # maps each model to a distinct RGB color\n",
    "    cmap = plt.cm.get_cmap(cmap, len(keys))\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    # for each model trained\n",
    "    for i, history in enumerate(models_history):\n",
    "        # take all pairs of training and val metrics\n",
    "        for j, metric in enumerate(keys):\n",
    "            plt.plot(history[metric], label=f\"{model_names[i]} {metric}\", linestyle=\"solid\", color=cmap(j))\n",
    "   \n",
    "    plt.xlabel(labels[0])\n",
    "    plt.ylabel(labels[1])\n",
    "    plt.yscale(y_scale)\n",
    "\n",
    "    # Adding legend\n",
    "    plt.legend(\n",
    "          title =\"Legend\",\n",
    "          loc =\"best\",\n",
    "          bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(\"Training history\")\n",
    "    plt.grid(linestyle='--', linewidth=1)\n",
    "    plt.show()\n",
    "\n",
    "model_history = [history]\n",
    "model_names = [\"BART fine-tuning\"]\n",
    "plot_history(model_history, keys=['loss', 'val_loss'], model_names=model_names, labels=(\"epochs\", \"loss\"), figsize=(6,3))\n",
    "plot_history(model_history, keys=['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], model_names=model_names, labels=(\"epochs\", \"rouge\"), figsize=(6,3), cmap=\"cool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Reading the test set\n",
    "In the evaluation stage, the test set consists of 1,027 episodes. It is provided in the [Spotify Podcast Dataset](https://podcastsdataset.byspotify.com/) separately from the training set, so we can use it to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  Index(['show_uri', 'show_name', 'show_description', 'publisher', 'language',\n",
      "       'rss_link', 'episode_uri', 'episode_name', 'episode_description',\n",
      "       'duration', 'show_filename_prefix', 'episode_filename_prefix'],\n",
      "      dtype='object')\n",
      "Shape:  (1027, 12)\n"
     ]
    }
   ],
   "source": [
    "metadata_path_test = os.path.join(dataset_path, \"spotify-podcasts-2020\", \"metadata-summarization-testset.tsv\")\n",
    "metadata_test = pd.read_csv(metadata_path_test, sep='\\t')\n",
    "print(\"Columns: \", metadata_test.columns)\n",
    "print(\"Shape: \", metadata_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size after dropping NaN values: \n",
      " (1025, 12)\n"
     ]
    }
   ],
   "source": [
    "# drop NaN values or empty descriptions if any\n",
    "metadata_test.dropna(subset=['episode_description', 'show_description'], inplace=True)\n",
    "metadata_test = metadata_test[[len(desc.strip()) > 0 for desc in metadata_test['episode_description']]]\n",
    "print(\"Test set size after dropping NaN values: \\n\", metadata_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer from the hub\n",
    "model_finetuned_checkpoint = \"gmurro/bart-large-finetuned-filtered-spotify-podcast-summ\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_finetuned_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Transcript filtering for the test set\n",
    "For each episode in then test set, extract the chunks from the transcript, classify them to evaluate their salience and take the ones with the highest score up to fulfill 1024 tokens. This step is necessary due to the limited length of the input sequence in BART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_classifier = keras.models.load_model(\"modelChunkNN\")\n",
    "sentence_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "metadata_test['filtered_transcript'] = metadata_test.progress_apply(lambda x: transcript_filtering(x, chunk_classifier, sentence_encoder, tokenizer, test_set=True), axis=1)\n",
    "\n",
    "metadata_test[['episode_uri','filtered_transcript', 'episode_description']].to_csv(os.path.join(dataset_path, \"filtered_testset.csv\"), index=False)\n",
    "print(\"Filtering done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluating the model\n",
    "We use the filtered transcripts as input for the evaluation. Our fine-tuned model is evaluated using the ROUGE metric and the BERTScore metric.\n",
    "We use the results to compare our model to the pretrained version of bart `bart-large-cnn` to quantify how well our model performs with respect to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-bae9440a6612428a\n",
      "Reusing dataset csv (C:\\Users\\peppe\\.cache\\huggingface\\datasets\\csv\\default-bae9440a6612428a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the filtered test set\n",
    "test_set = load_dataset('csv', data_files=os.path.join(dataset_path, \"filtered_testset.csv\"))['train']\n",
    "print(f\"Test set size: {test_set.num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_tf(dataset, tokenizer, model, max_input_length = 1024, max_target_length = 256, eval_batch_size = 2):\n",
    "    \"\"\"\n",
    "    Convert a dataset to a tensorflow dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : Dataset\n",
    "        The dataset to convert.\n",
    "    tokenizer : AutoTokenizer\n",
    "        The tokenizer to use.\n",
    "    model : TFAutoModelForSeq2SeqLM\n",
    "        The model to use.\n",
    "    max_input_length : int\n",
    "        The maximum length of the input sequences. Default: 1024.\n",
    "    max_target_length : int\n",
    "        The maximum length of the target sequences. Default: 256.\n",
    "    eval_batch_size : int\n",
    "        The batch size used for evaluation. Default: 2.\n",
    "    \"\"\"\n",
    "\n",
    "    # tokenize the set\n",
    "    set_tokenized = dataset.map(\n",
    "        lambda batch: batch_tokenize_preprocess(\n",
    "            batch, \"filtered_transcript\", \"episode_description\", tokenizer, max_input_length, max_target_length\n",
    "        ),\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names,\n",
    "        desc=\"Running tokenizer on the given dataset\"\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")\n",
    "\n",
    "    dataset_tf  = set_tokenized.to_tf_dataset(\n",
    "        batch_size=eval_batch_size,\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    return dataset_tf\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def predict(test_dataset, model, tokenizer, gen_kwargs, eval_batch_size):\n",
    "    \"\"\"\n",
    "    Generate predictions for the test set\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_dataset : datasets.Dataset\n",
    "        Test set\n",
    "    model : tf.keras.Model\n",
    "        Model to use for generation\n",
    "    tokenizer : transformers.AutoTokenizer\n",
    "        Tokenizer to use for generation\n",
    "    gen_kwargs : dict\n",
    "        Keyword arguments for the generation\n",
    "    eval_batch_size : int\n",
    "        Batch size for evaluation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pair correspoding to the list of predictions and the list of labels\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    references  = []\n",
    "\n",
    "    # convert the dataset to a tensorflow dataset prebatched\n",
    "    testset_tf = dataset_to_tf(test_dataset, tokenizer, model, max_input_length = 1024, max_target_length = 256, eval_batch_size = eval_batch_size)\n",
    "\n",
    "    # generate the predicted summaries\n",
    "    for batch in tqdm(testset_tf, desc=\"Generating summaries\", total=len(test_dataset)//eval_batch_size):\n",
    "        labels = batch.pop(\"labels\")\n",
    "        batch.update(gen_kwargs)\n",
    "        generated_tokens = model.generate(**batch)\n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "        predictions.extend(decoded_preds)\n",
    "        references.extend(decoded_labels)\n",
    "    return predictions, references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters used by BART during the generation are the same defined by Song et al. (2020) in their [paper](https://arxiv.org/abs/2011.04132) submitted on TREC 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at gmurro/bart-large-finetuned-filtered-spotify-podcast-summ.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_finetuned = \"gmurro/bart-large-finetuned-filtered-spotify-podcast-summ\" \n",
    "tokenizer_finetuned = AutoTokenizer.from_pretrained(model_checkpoint_finetuned)\n",
    "model_finetuned = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint_finetuned)\n",
    "\n",
    "model_checkpoint_pretrained = \"facebook/bart-large-cnn\"\n",
    "tokenizer_pretrained = AutoTokenizer.from_pretrained(model_checkpoint_pretrained)\n",
    "model_pretrained = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tokenizer on the given dataset: 100%|██████████| 1/1 [00:00<00:00, 62.62ba/s]\n",
      "Generating summaries: 100%|██████████| 513/513 [13:44:15<00:00, 96.40s/it]\n",
      "Generating summaries: 100%|██████████| 513/513 [13:24:11<00:00, 94.30s/it]\n",
      "Predictions done!\n"
     ]
    }
   ],
   "source": [
    "# bart generation parameters\n",
    "gen_kwargs = {\n",
    "    \"length_penalty\": 2.0,\n",
    "    \"num_beams\": 4,\n",
    "    \"no_repeat_ngram_size\": 3,\n",
    "    \"min_length\": 39,\n",
    "    \"max_length\": 250\n",
    "    }\n",
    "\n",
    "# predict on the test set with the finetuned model\n",
    "predictions_ft, references_ft = predict(test_set, model_finetuned, tokenizer_finetuned, gen_kwargs, eval_batch_size=2)  \n",
    "\n",
    "# predict on the test set with the pretrained model\n",
    "predictions_pt, references_pt = predict(test_set, model_pretrained, tokenizer_pretrained, gen_kwargs, eval_batch_size=1)\n",
    "print(\"Predictions done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize predictions using both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This episode is full, and we mean FULL, of behavioral principles. Dr. Steve Kurtz reached out to us after hearing guest Chelsea (Outloud Podcast) talk about Selective Mutism. Steve in an internationally recognized expert #BFD in child psychology. He is also the founder of the Selective Mutism Programs at both the NYU Child Study Center and the Child Mind Institute. In his email to us he said let’s talk about “awesome ABA implemented in a non-autistic context.” It was almost like he knew what we did over here at BBP. Steve instantly became one of our favorite guests and an honorary Behavior B. Steve also sent us both pins that say, “Get Comfortable, Being Uncomfortable.” I mean this guy is the real deal. You are going to love this conversation as much as we did, promise. Love you. Mean it. Show Notes:   Selectivemutismlearning.org   https://www.kurtzpsychology.com/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_ft[10].replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creator-provided description: \n",
      "\tMallory Rubin addresses the handwritten expression of gratitude.\n",
      "Fine-tuned model prediction: \n",
      "\tAmanda and Emily discuss the joy of a handwritten thank you note. They also discuss the social contract that keeps us in a cycle of obligation and obligation and how to break out of it.\n",
      "Pre-trained model prediction: \n",
      "\tAmanda Fosters says handwritten thank-you notes perpetuate a cycle of obligation. She says there are a lot of other ways to show gratitude. \"There's nothing more exciting and this day and age than getting an unsolicited nice thing in the mail\"\n",
      "\n",
      "\n",
      "Creator-provided description: \n",
      "\tHealth Mantra   ---   This episode is sponsored by  · Anchor: The easiest way to make a podcast. https://anchor.fm/app  Support this podcast: https://anchor.fm/RaniaJaziri/support\n",
      "Fine-tuned model prediction: \n",
      "\tEveryday is a new day full of hope, happiness and health. I m getting healthier and healthier and feeling better and better. I always feel good and as a result my body feels good and I radiate good feelings.\n",
      "Pre-trained model prediction: \n",
      "\tanchor is the easiest way to make a podcast and it's free their creation tools that you can use to record and edit your podcast from your phone and your computer an anchor will distribute the podcast for you. So you can be heard on every platform such as Spotify and apple you can even make money from your podcast.\n",
      "\n",
      "\n",
      "Creator-provided description: \n",
      "\tIn our debut episode for our Traveller rpg actual play campaign our heroes meet and (after a jump drive failure) crash land. Tune in and join our adventure! Our Imperium actual play games use the Traveller RPG (Mongoose 2nd Edition). Background music and ambient sounds provided by Tabletopaudio.com. Intro music is Stock Media provided by Pond5.\n",
      "Fine-tuned model prediction: \n",
      "\tIn this episode, the crew set off on their first mission to Zemus, a system in the Concordian sub-sector of space. They find themselves in the midst of a fight with a gas giant, and the crew must figure out what to do about it.\n",
      "Pre-trained model prediction: \n",
      "\tI play Reuben Glaser a harpoon, which is a dog race are and get used to that. So there's no recap to do because this is our first episode ever, but we're going to start off actually at Zemus. So yeah, I'm the type of guy that has like, you know, 50 windows open. I'm like moving in between them.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_to_visualize = 3\n",
    "\n",
    "for _ in range(num_to_visualize):\n",
    "    i = np.random.randint(0, len(references_ft))\n",
    "\n",
    "    ref = references_ft[i].replace('\\n', ' ')\n",
    "    ft = predictions_ft[i].replace('\\n', ' ')\n",
    "    pt = predictions_pt[i].replace('\\n', ' ')\n",
    "    print(f\"Creator-provided description: \\n\\t{ref}\")\n",
    "    print(f\"Fine-tuned model prediction: \\n\\t{ft}\")\n",
    "    print(f\"Pre-trained model prediction: \\n\\t{pt}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read predictions and references (if stored)\n",
    "df_pred = pd.read_csv(os.path.join(dataset_path, \"predictions_ft.csv\"))\n",
    "predictions_ft = df_pred['predictions'].tolist()\n",
    "references_ft = df_pred['references'].tolist()\n",
    "\n",
    "df_pred = pd.read_csv(os.path.join(dataset_path, \"predictions_pt.csv\"))\n",
    "predictions_pt = df_pred['predictions'].tolist()\n",
    "references_pt = df_pred['references'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation using ROUGE and BERTScore as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_evaluation(predictions, references):\n",
    "    \"\"\"\n",
    "    Evaluate the ROUGE score for the given predictions and references\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : list\n",
    "        List of predictions\n",
    "    references : list\n",
    "        List of references\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        ROUGE score\n",
    "    \"\"\"\n",
    "    rouge = evaluate.load('rouge')\n",
    "    results_rouge = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "\n",
    "    df_rouge = pd.DataFrame({'precision': [round(value.mid.precision,4) for key, value in results_rouge.items()],\n",
    "                             'recall': [round(value.mid.recall,4) for key, value in results_rouge.items()],  \n",
    "                             'f1': [round(value.mid.fmeasure,4) for key, value in results_rouge.items()]},\n",
    "                             index=results_rouge.keys())\n",
    "\n",
    "    return df_rouge\n",
    "\n",
    "def bertscore_evaluation(predictions, references, idf_weighting=True):\n",
    "    \"\"\"\n",
    "    Evaluate the BERTScore score for the given predictions and references\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : list\n",
    "        List of predictions\n",
    "    references : list\n",
    "        List of references\n",
    "    idf_weighting : bool\n",
    "        Whether to use idf weighting\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        BERTScore score\n",
    "    \"\"\"\n",
    "    precision, recall, fmeasure = bert_score.score(cands=predictions, refs=references, lang=\"en\", model_type=\"microsoft/deberta-xlarge-mnli\", num_layers=40, idf=idf_weighting)\n",
    "    df_bertscore = pd.DataFrame({'precision': [round(precision.mean().item(), 4), round(precision.std().item(), 4)],\n",
    "                                 'recall': [round(recall.mean().item(), 4), round(recall.std().item(),4)],\n",
    "                                 'f1': [round(fmeasure.mean().item(), 4), round(fmeasure.std().item(),4)]},\n",
    "                             index=[\"mean\", \"std\"])\n",
    "\n",
    "    return df_bertscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Evaluation of the fine-tuned model `bart-large-finetuned-filtered-spotify-podcast-summ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge1</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.2370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2</th>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeL</th>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeLsum</th>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.2058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision  recall      f1\n",
       "rouge1        0.3250  0.2315  0.2370\n",
       "rouge2        0.0884  0.0677  0.0670\n",
       "rougeL        0.2160  0.1634  0.1621\n",
       "rougeLsum     0.2846  0.2003  0.2058"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the ROUGE score on fine-tuned model\n",
    "rouge_ft = rouge_evaluation(predictions_ft, references_ft)\n",
    "rouge_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.8401</td>\n",
       "      <td>0.8093</td>\n",
       "      <td>0.8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.0327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  recall      f1\n",
       "mean     0.8401  0.8093  0.8240\n",
       "std      0.0335  0.0422  0.0327"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the BERT score with IDF on fine-tuned model\n",
    "bertscore_ft = bertscore_evaluation(predictions_ft, references_ft, idf_weighting=True)\n",
    "bertscore_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.8631</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.8447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  recall      f1\n",
       "mean     0.8631  0.8279  0.8447\n",
       "std      0.0286  0.0411  0.0299"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the BERT score without IDF on fine-tuned model\n",
    "bertscore_ft = bertscore_evaluation(predictions_ft, references_ft, idf_weighting=False)\n",
    "bertscore_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Evaluation of the pretrained model `bart-large-cnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge1</th>\n",
       "      <td>0.2357</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2</th>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeL</th>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeLsum</th>\n",
       "      <td>0.2088</td>\n",
       "      <td>0.1855</td>\n",
       "      <td>0.1684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision  recall      f1\n",
       "rouge1        0.2357  0.2125  0.1917\n",
       "rouge2        0.0449  0.0447  0.0379\n",
       "rougeL        0.1467  0.1408  0.1223\n",
       "rougeLsum     0.2088  0.1855  0.1684"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the ROUGE score\n",
    "rouge_pt = rouge_evaluation(predictions_pt, references_pt)\n",
    "rouge_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.8018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  recall      f1\n",
       "mean     0.8103  0.7941  0.8018\n",
       "std      0.0247  0.0388  0.0277"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the BERT score with IDF on pre-trained model\n",
    "bertscore_pt = bertscore_evaluation(predictions_pt, references_pt, idf_weighting=True)\n",
    "bertscore_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.8121</td>\n",
       "      <td>0.8214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  recall      f1\n",
       "mean     0.8317  0.8121  0.8214\n",
       "std      0.0232  0.0373  0.0262"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the BERT score without IDF on pre-trained model\n",
    "bertscore_pt = bertscore_evaluation(predictions_pt, references_pt, idf_weighting=False)\n",
    "bertscore_pt"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e800dd11dddfb1e3886769e91ed8bbe987a221798b85010fca298ae8afbc389e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
